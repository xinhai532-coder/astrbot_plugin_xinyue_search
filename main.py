import asyncio
import aiohttp
import yaml
import os
import time
from urllib.parse import urlparse, parse_qs
from astrbot.api.event import filter, AstrMessageEvent, MessageEventResult
from astrbot.api.star import Context, Star, register
from astrbot.api import logger
from typing import Dict, List
from collections import defaultdict


class RateLimiter:
    """è¯·æ±‚é™æµå™¨ - æ»‘åŠ¨çª—å£ç®—æ³•"""
    
    def __init__(self, max_requests: int = 10, window_seconds: int = 60):
        """
        åˆå§‹åŒ–é™æµå™¨
        :param max_requests: çª—å£æœŸå†…æœ€å¤§è¯·æ±‚æ•°
        :param window_seconds: çª—å£æœŸæ—¶é•¿ï¼ˆç§’ï¼‰
        """
        self.max_requests = max_requests
        self.window_seconds = window_seconds
        self.requests: Dict[str, List[float]] = defaultdict(list)
    
    def is_allowed(self, user_id: str) -> bool:
        """
        æ£€æŸ¥ç”¨æˆ·æ˜¯å¦å…è®¸è¯·æ±‚
        :param user_id: ç”¨æˆ·æ ‡è¯†
        :return: True å…è®¸ï¼ŒFalse æ‹’ç»
        """
        now = time.time()
        # æ¸…ç†è¿‡æœŸçš„è¯·æ±‚è®°å½•
        self.requests[user_id] = [
            t for t in self.requests[user_id] 
            if now - t < self.window_seconds
        ]
        # æ£€æŸ¥æ˜¯å¦è¶…è¿‡é™åˆ¶
        if len(self.requests[user_id]) >= self.max_requests:
            return False
        # è®°å½•æœ¬æ¬¡è¯·æ±‚
        self.requests[user_id].append(now)
        return True
    
    def get_wait_time(self, user_id: str) -> int:
        """è·å–ç”¨æˆ·éœ€è¦ç­‰å¾…çš„ç§’æ•°"""
        if not self.requests[user_id]:
            return 0
        oldest = min(self.requests[user_id])
        wait = self.window_seconds - (time.time() - oldest)
        return max(0, int(wait))


@register("astrbot_plugin_xinyue_search", "é˜¿ç«‹", "å¿ƒæ‚¦æœç´¢æœºå™¨äººæ’ä»¶", "1.3.6")
class XinyueSearchBotPlugin(Star):
    def __init__(self, context: Context, config: dict = None):
        super().__init__(context)
        # å¦‚æœconfigä¸ºNoneï¼Œä½¿ç”¨ç©ºå­—å…¸
        if config is None:
            config = {}

        # é€‚é…AstrBoté…ç½®æ¨¡å¼ï¼Œå°†å¤–éƒ¨é…ç½®é”®æ˜ å°„åˆ°å†…éƒ¨é…ç½®
        self.config = {
            # APIåŸºç¡€é…ç½® - é€‚é…å¤–éƒ¨é…ç½®é”®
            'base_url': config.get('api_url', 'https://youdomain.com').rstrip('/'),
            'api_key': config.get('api_key', ''),

            # æœç´¢é…ç½®
            'max_retries': config.get('max_retries', 3),
            'search_timeout': config.get('timeout', 10),
            'transfer_timeout': config.get('transfer_timeout', 30),
            'results_per_page': config.get('max_results', 5),

            # è½¬å­˜åŠŸèƒ½é…ç½®
            'enable_transfer': config.get('enable_transfer', True),
            'transfer_delay': config.get('transfer_delay', 1),

            # æ—¥å¿—é…ç½®
            'log_level': 'INFO',
            'log_format': '%(asctime)s - %(name)s - %(levelname)s - %(message)s',

            # æœç´¢ç±»å‹é…ç½®ï¼ˆå¯è‡ªå®šä¹‰ï¼‰
            'search_types': {
                'å¤¸å…‹': 0,
                'ç™¾åº¦': 2,
                'UC': 3,
                'è¿…é›·': 4
            },

            # æŒ‡ä»¤é…ç½®ï¼ˆå¯è‡ªå®šä¹‰ï¼‰
            'search_commands': {
                'æœ': 'å¤¸å…‹',
                'ç™¾åº¦': 'ç™¾åº¦',
                'uc': 'UC',
                'UC': 'UC',
                'è¿…é›·': 'è¿…é›·'
            },

            # å“åº”æ¶ˆæ¯é…ç½®
            'messages': {
                'searching': 'å…¨ç½‘æœç´¢ä¸­ï¼Œè¯·ç¨ç­‰ç‰‡åˆ»â€¦â€¦',
                'no_results': 'æœªæ‰¾åˆ°ç›¸å…³èµ„æº',
                'search_error': 'æœç´¢è¿‡ç¨‹ä¸­å‘ç”Ÿé”™è¯¯ï¼Œè¯·ç¨åé‡è¯•',
                'transfer_success': 'âœ… è½¬å­˜æˆåŠŸï¼\nğŸ“ èµ„æºæ ‡é¢˜ï¼š{0}\nğŸ”— åˆ†äº«é“¾æ¥ï¼š{1}',
                'transfer_disabled': 'âŒ è½¬å­˜åŠŸèƒ½æœªå¯ç”¨',
                'api_key_required': 'âŒ éœ€è¦é…ç½®APIå¯†é’¥æ‰èƒ½ä½¿ç”¨è½¬å­˜åŠŸèƒ½',
                'baidu_format_error': 'æŒ‡ä»¤æ ¼å¼é”™è¯¯ï¼Œè¯·ä½¿ç”¨ï¼šç™¾åº¦èµ„æºåç§°',
                'baidu_example': 'è¯·è¾“å…¥è¦æœç´¢çš„èµ„æºåç§°ï¼Œä¾‹å¦‚ï¼šç™¾åº¦{0}',
                'uc_format_error': 'æŒ‡ä»¤æ ¼å¼é”™è¯¯ï¼Œè¯·ä½¿ç”¨ï¼šucèµ„æºåç§°',
                'uc_example': 'è¯·è¾“å…¥è¦æœç´¢çš„èµ„æºåç§°ï¼Œä¾‹å¦‚ï¼šuc{0}',
                'uc_upper_format_error': 'æŒ‡ä»¤æ ¼å¼é”™è¯¯ï¼Œè¯·ä½¿ç”¨ï¼šUCèµ„æºåç§°',
                'uc_upper_example': 'è¯·è¾“å…¥è¦æœç´¢çš„èµ„æºåç§°ï¼Œä¾‹å¦‚ï¼šUC{0}',
                'xunlei_format_error': 'æŒ‡ä»¤æ ¼å¼é”™è¯¯ï¼Œè¯·ä½¿ç”¨ï¼šè¿…é›·èµ„æºåç§°',
                'xunlei_example': 'è¯·è¾“å…¥è¦æœç´¢çš„èµ„æºåç§°ï¼Œä¾‹å¦‚ï¼šè¿…é›·{0}',
                'last_page': 'å·²ç»æ˜¯æœ€åä¸€é¡µäº†',
                'no_search_session': 'æ²¡æœ‰æ‰¾åˆ°æœç´¢ä¼šè¯ï¼Œè¯·å…ˆè¿›è¡Œæœç´¢',
                'next_page_error': 'è·å–ä¸‹ä¸€é¡µå¤±è´¥ï¼Œè¯·ç¨åé‡è¯•',
                'first_page': 'å·²ç»æ˜¯ç¬¬ä¸€é¡µäº†',
                'previous_page_error': 'è·å–ä¸Šä¸€é¡µå¤±è´¥ï¼Œè¯·ç¨åé‡è¯•',
                'invalid_transfer_command': 'âŒ æ— æ•ˆçš„è½¬å­˜æŒ‡ä»¤æ ¼å¼',
                'no_search_for_transfer': 'âŒ æ²¡æœ‰æ‰¾åˆ°å¯è½¬å­˜çš„æœç´¢ç»“æœ',
                'search_expired': 'âŒ æœç´¢ä¼šè¯å·²è¿‡æœŸï¼Œè¯·é‡æ–°æœç´¢',
                'invalid_resource_index': 'âŒ æ— æ•ˆçš„èµ„æºåºå·ï¼Œè¯·è¾“å…¥1-{0}ä¹‹é—´çš„æ•°å­—',
                'no_valid_link': 'âŒ è¯¥èµ„æºæ²¡æœ‰æœ‰æ•ˆçš„åˆ†äº«é“¾æ¥',
                'only_quark_support': 'âŒ ç›®å‰ä»…æ”¯æŒå¤¸å…‹ç½‘ç›˜è½¬å­˜',
                'transferring': 'æ­£åœ¨è½¬å­˜ã€Š{0}ã€‹ï¼Œè¯·ç¨å€™...',
                'transfer_error': 'âŒ è½¬å­˜å¤±è´¥ï¼Œè¯·ç¨åé‡è¯•',
                'empty_keyword': 'âŒ æœç´¢å…³é”®è¯ä¸èƒ½ä¸ºç©º',
                'keyword_too_long': 'âŒ æœç´¢å…³é”®è¯è¿‡é•¿ï¼ˆè¶…è¿‡100å­—ç¬¦ï¼‰',
                'parse_search_failed': 'âŒ è§£ææœç´¢ç»“æœå¤±è´¥',
                'too_many_requests': 'âŒ è¯·æ±‚è¿‡äºé¢‘ç¹ï¼Œè¯·ç¨åå†è¯•',
                'search_service_unavailable': 'âŒ æœç´¢æœåŠ¡å¼‚å¸¸ï¼ŒHTTPçŠ¶æ€ç ï¼š{0}',
                'search_timeout': 'âŒ æœç´¢è¶…æ—¶ï¼Œè¯·ç¨åé‡è¯•',
                'network_error': 'âŒ ç½‘ç»œé”™è¯¯ï¼Œè¯·æ£€æŸ¥ç½‘ç»œè¿æ¥',
                'unknown_search_error': 'âŒ æœç´¢å‘ç”ŸæœªçŸ¥é”™è¯¯ï¼š{0}',
                'search_service_unavailable_temporarily': 'æœåŠ¡æš‚æ—¶ä¸å¯ç”¨',
                'search_failed': 'æœç´¢å¤±è´¥',
                'full_network_search_results': 'ğŸ” å…¨ç½‘æœç´¢ç»“æœï¼š{0}\n\n',
                'api_key_not_configured': 'âŒ APIå¯†é’¥æœªé…ç½®ï¼Œè¯·è”ç³»ç®¡ç†å‘˜é…ç½®api_key',
                'search_command_format_error': 'æŒ‡ä»¤æ ¼å¼é”™è¯¯ï¼Œè¯·ä½¿ç”¨ï¼š{0}èµ„æºåç§°',
                'search_example_format': 'è¯·è¾“å…¥è¦æœç´¢çš„èµ„æºåç§°ï¼Œä¾‹å¦‚ï¼š{0}{1}',
                'search_unknown_error': '{0}æœç´¢è¿‡ç¨‹ä¸­å‘ç”ŸæœªçŸ¥é”™è¯¯ï¼Œè¯·ç¨åé‡è¯•',
                'keyword_empty_error': 'æœç´¢å…³é”®è¯ä¸èƒ½ä¸ºç©º',
                'keyword_too_long_error': 'æœç´¢å…³é”®è¯è¿‡é•¿ï¼Œè¯·ç¼©çŸ­åé‡è¯•',
                'search_no_results_format': 'æœªæ‰¾åˆ°ä¸\'{0}\'ç›¸å…³çš„èµ„æº',
                'search_too_many_requests': 'è¯·æ±‚è¿‡äºé¢‘ç¹ï¼Œè¯·ç¨åå†è¯•',
                'search_service_unavailable_format': 'æœç´¢æœåŠ¡æš‚æ—¶ä¸å¯ç”¨ï¼ŒHTTPçŠ¶æ€ç : {0}',
                'search_timeout_error': 'æœç´¢è¶…æ—¶ï¼Œè¯·ç¨åé‡è¯•',
                'network_connection_error': 'ç½‘ç»œè¿æ¥å¼‚å¸¸ï¼Œè¯·æ£€æŸ¥ç½‘ç»œåé‡è¯•',
                'search_service_temporarily_unavailable': 'æœç´¢æœåŠ¡æš‚æ—¶ä¸å¯ç”¨ï¼Œè¯·ç¨åé‡è¯•',
                'search_unknown_error_format': 'æœç´¢è¿‡ç¨‹ä¸­å‘ç”ŸæœªçŸ¥é”™è¯¯: {0}',
                'search_results_parse_failed': 'æœç´¢ç»“æœè§£æå¤±è´¥ï¼Œè¯·ç¨åé‡è¯•',
                'no_previous_search': 'æ‚¨è¿˜æ²¡æœ‰è¿›è¡Œæœç´¢ï¼Œè¯·å…ˆä½¿ç”¨æœç´¢æŒ‡ä»¤ï¼Œä¾‹å¦‚ï¼š\næœç”µå½±å\nç™¾åº¦ç”µå½±å\nucç”µå½±å\nè¿…é›·ç”µå½±å',
                'next_page_unknown_error': 'å¤„ç†ä¸‹ä¸€é¡µæŒ‡ä»¤æ—¶å‘ç”ŸæœªçŸ¥é”™è¯¯ï¼Œè¯·ç¨åé‡è¯•',
                'previous_page_unknown_error': 'å¤„ç†ä¸Šä¸€é¡µæŒ‡ä»¤æ—¶å‘ç”ŸæœªçŸ¥é”™è¯¯ï¼Œè¯·ç¨åé‡è¯•',
                'transfer_failed': 'âŒ è½¬å­˜å¤±è´¥ï¼š{0}',
                'transfer_service_error': 'âŒ è½¬å­˜æœåŠ¡å¼‚å¸¸ï¼ŒHTTPçŠ¶æ€ç ï¼š{0}',
                'transfer_timeout': 'âŒ è½¬å­˜è¶…æ—¶ï¼Œè¯·ç¨åé‡è¯•',
                'transfer_process_error': 'âŒ è½¬å­˜è¿‡ç¨‹ä¸­å‘ç”Ÿé”™è¯¯ï¼š{0}',
                'show_config_error': 'æ˜¾ç¤ºé…ç½®ä¿¡æ¯æ—¶å‘ç”Ÿé”™è¯¯',
                'unknown_error': 'æœªçŸ¥é”™è¯¯',
                'invalid_page_number': 'âŒ é¡µç è¶…å‡ºèŒƒå›´ï¼Œæ€»é¡µæ•°ä¸º{0}',
                'format_search_error': 'âŒ æ ¼å¼åŒ–æœç´¢ç»“æœå¤±è´¥',
                'resource_title_default': 'æœªçŸ¥æ ‡é¢˜',
                'resource_link_format': '{0}. {1}\né“¾æ¥: `{2}`',
                'resource_title_format': '{0}. {1}',
                'quark_transfer_prompt': 'ğŸ’¡ å›å¤"è½¬å­˜{0}"å¯è½¬å­˜åˆ°å¤¸å…‹ç½‘ç›˜',
                'search_results_header': 'ğŸ” å…±æ‰¾åˆ° {0} ä¸ªç›¸å…³èµ„æºï¼š',
                'search_results_separator': 'â”€' * 14,
                'search_results_footer': 'é“¾æ¥æœ‰æ•ˆæœŸ5åˆ†é’Ÿï¼Œè¿‡æœŸè¯·é‡æœ',
                'search_results_separator_footer': 'â”€' * 14,
                'search_results_website_promo': 'æ›´å¤šèµ„æºè¯·ä¸Š {0}',
                'search_results_page_info': 'ğŸ“„ ç¬¬ {0}/{1} é¡µ',
                'search_results_navigation': 'ğŸ’¡ å›å¤"ä¸Š/ä¸‹"æˆ–"0/1"ç¿»é¡µ',
                'no_resources_found': 'æœªæ‰¾åˆ°ç›¸å…³èµ„æº: {0}\n\nğŸ’¡ æç¤ºï¼šè¯·å°è¯•å…¶ä»–ç½‘ç›˜æœç´¢'
            }
        }

        # ä»é…ç½®ä¸­æå–å¸¸ç”¨å‚æ•°
        self.base_url = self.config['base_url']
        self.api_key = self.config['api_key']
        self.max_retries = self.config['max_retries']
        self.search_timeout = self.config['search_timeout']
        self.transfer_timeout = self.config['transfer_timeout']
        self.results_per_page = self.config['results_per_page']
        self.enable_transfer = self.config['enable_transfer']
        self.enable_pagination = config.get('enable_pagination', True)  # æ˜¯å¦å¯ç”¨åˆ†é¡µåŠŸèƒ½
        self.transfer_delay = self.config['transfer_delay']
        self.search_types = self.config['search_types']
        self.search_commands = self.config['search_commands']
        self.messages = self.config['messages']

        # åˆå§‹åŒ–é™æµå™¨
        self.rate_limiter = RateLimiter(max_requests=10, window_seconds=60)
        
        # ç”¨æˆ·ä¼šè¯çŠ¶æ€å­˜å‚¨ï¼Œç”¨äºåˆ†é¡µåŠŸèƒ½
        self.user_sessions: Dict[str, Dict] = {}
        
        # Cookieç¼“å­˜ï¼ˆé¿å…é‡å¤è¯·æ±‚ï¼‰
        self._cookie_cache: Dict[str, tuple] = {}  # {pan_type: (cookie_value, timestamp)}

    def _load_config(self) -> dict:
        """åŠ è½½é…ç½®æ–‡ä»¶"""
        config_file = os.path.join(os.path.dirname(__file__), 'config.yaml')
        default_config = {
            'base_url': 'https://youdomain.com',
            'api_key': '',
            'max_retries': 3,
            'search_timeout': 10,
            'transfer_timeout': 30,
            'results_per_page': 5,
            'enable_transfer': True,
            'transfer_delay': 1,
            'log_level': 'INFO',
            # é»˜è®¤æ¶ˆæ¯é…ç½®
            'messages': {
                'searching': 'å…¨ç½‘æœç´¢ä¸­ï¼Œè¯·ç¨ç­‰ç‰‡åˆ»â€¦â€¦',
                'no_results': 'æœªæ‰¾åˆ°ç›¸å…³èµ„æº',
                'search_error': 'æœç´¢è¿‡ç¨‹ä¸­å‘ç”Ÿé”™è¯¯ï¼Œè¯·ç¨åé‡è¯•',
                'transfer_success': 'âœ… è½¬å­˜æˆåŠŸï¼\nğŸ“ èµ„æºæ ‡é¢˜ï¼š{0}\nğŸ”— åˆ†äº«é“¾æ¥ï¼š{1}',
                'transfer_disabled': 'âŒ è½¬å­˜åŠŸèƒ½æœªå¯ç”¨',
                'api_key_required': 'âŒ éœ€è¦é…ç½®APIå¯†é’¥æ‰èƒ½ä½¿ç”¨è½¬å­˜åŠŸèƒ½',
                'baidu_format_error': 'æŒ‡ä»¤æ ¼å¼é”™è¯¯ï¼Œè¯·ä½¿ç”¨ï¼šç™¾åº¦èµ„æºåç§°',
                'baidu_example': 'è¯·è¾“å…¥è¦æœç´¢çš„èµ„æºåç§°ï¼Œä¾‹å¦‚ï¼šç™¾åº¦{0}',
                'uc_format_error': 'æŒ‡ä»¤æ ¼å¼é”™è¯¯ï¼Œè¯·ä½¿ç”¨ï¼šucèµ„æºåç§°',
                'uc_example': 'è¯·è¾“å…¥è¦æœç´¢çš„èµ„æºåç§°ï¼Œä¾‹å¦‚ï¼šuc{0}',
                'uc_upper_format_error': 'æŒ‡ä»¤æ ¼å¼é”™è¯¯ï¼Œè¯·ä½¿ç”¨ï¼šUCèµ„æºåç§°',
                'uc_upper_example': 'è¯·è¾“å…¥è¦æœç´¢çš„èµ„æºåç§°ï¼Œä¾‹å¦‚ï¼šUC{0}',
                'xunlei_format_error': 'æŒ‡ä»¤æ ¼å¼é”™è¯¯ï¼Œè¯·ä½¿ç”¨ï¼šè¿…é›·èµ„æºåç§°',
                'xunlei_example': 'è¯·è¾“å…¥è¦æœç´¢çš„èµ„æºåç§°ï¼Œä¾‹å¦‚ï¼šè¿…é›·{0}',
                'last_page': 'å·²ç»æ˜¯æœ€åä¸€é¡µäº†',
                'no_search_session': 'æ²¡æœ‰æ‰¾åˆ°æœç´¢ä¼šè¯ï¼Œè¯·å…ˆè¿›è¡Œæœç´¢',
                'next_page_error': 'è·å–ä¸‹ä¸€é¡µå¤±è´¥ï¼Œè¯·ç¨åé‡è¯•',
                'first_page': 'å·²ç»æ˜¯ç¬¬ä¸€é¡µäº†',
                'previous_page_error': 'è·å–ä¸Šä¸€é¡µå¤±è´¥ï¼Œè¯·ç¨åé‡è¯•',
                'invalid_transfer_command': 'âŒ æ— æ•ˆçš„è½¬å­˜æŒ‡ä»¤æ ¼å¼',
                'no_search_for_transfer': 'âŒ æ²¡æœ‰æ‰¾åˆ°å¯è½¬å­˜çš„æœç´¢ç»“æœ',
                'search_expired': 'âŒ æœç´¢ä¼šè¯å·²è¿‡æœŸï¼Œè¯·é‡æ–°æœç´¢',
                'invalid_resource_index': 'âŒ æ— æ•ˆçš„èµ„æºåºå·ï¼Œè¯·è¾“å…¥1-{0}ä¹‹é—´çš„æ•°å­—',
                'no_valid_link': 'âŒ è¯¥èµ„æºæ²¡æœ‰æœ‰æ•ˆçš„åˆ†äº«é“¾æ¥',
                'only_quark_support': 'âŒ ç›®å‰ä»…æ”¯æŒå¤¸å…‹ç½‘ç›˜è½¬å­˜',
                'transferring': 'æ­£åœ¨è½¬å­˜ã€Š{0}ã€‹ï¼Œè¯·ç¨å€™...',
                'transfer_error': 'âŒ è½¬å­˜å¤±è´¥ï¼Œè¯·ç¨åé‡è¯•',
                'empty_keyword': 'âŒ æœç´¢å…³é”®è¯ä¸èƒ½ä¸ºç©º',
                'keyword_too_long': 'âŒ æœç´¢å…³é”®è¯è¿‡é•¿ï¼ˆè¶…è¿‡100å­—ç¬¦ï¼‰',
                'parse_search_failed': 'âŒ è§£ææœç´¢ç»“æœå¤±è´¥',
                'too_many_requests': 'âŒ è¯·æ±‚è¿‡äºé¢‘ç¹ï¼Œè¯·ç¨åå†è¯•',
                'search_service_unavailable': 'âŒ æœç´¢æœåŠ¡å¼‚å¸¸ï¼ŒHTTPçŠ¶æ€ç ï¼š{0}',
                'search_timeout': 'âŒ æœç´¢è¶…æ—¶ï¼Œè¯·ç¨åé‡è¯•',
                'network_error': 'âŒ ç½‘ç»œé”™è¯¯ï¼Œè¯·æ£€æŸ¥ç½‘ç»œè¿æ¥',
                'unknown_search_error': 'âŒ æœç´¢å‘ç”ŸæœªçŸ¥é”™è¯¯ï¼š{0}',
                'search_service_unavailable_temporarily': 'æœåŠ¡æš‚æ—¶ä¸å¯ç”¨',
                'search_failed': 'æœç´¢å¤±è´¥',
                'full_network_search_results': 'ğŸ” å…¨ç½‘æœç´¢ç»“æœï¼š{0}\n\n',
                'api_key_not_configured': 'âŒ APIå¯†é’¥æœªé…ç½®ï¼Œè¯·è”ç³»ç®¡ç†å‘˜é…ç½®api_key',
                'search_command_format_error': 'æŒ‡ä»¤æ ¼å¼é”™è¯¯ï¼Œè¯·ä½¿ç”¨ï¼š{0}èµ„æºåç§°',
                'search_example_format': 'è¯·è¾“å…¥è¦æœç´¢çš„èµ„æºåç§°ï¼Œä¾‹å¦‚ï¼š{0}{1}',
                'search_unknown_error': '{0}æœç´¢è¿‡ç¨‹ä¸­å‘ç”ŸæœªçŸ¥é”™è¯¯ï¼Œè¯·ç¨åé‡è¯•',
                'keyword_empty_error': 'æœç´¢å…³é”®è¯ä¸èƒ½ä¸ºç©º',
                'keyword_too_long_error': 'æœç´¢å…³é”®è¯è¿‡é•¿ï¼Œè¯·ç¼©çŸ­åé‡è¯•',
                'search_no_results_format': 'æœªæ‰¾åˆ°ä¸\'{0}\'ç›¸å…³çš„èµ„æº',
                'search_too_many_requests': 'è¯·æ±‚è¿‡äºé¢‘ç¹ï¼Œè¯·ç¨åå†è¯•',
                'search_service_unavailable_format': 'æœç´¢æœåŠ¡æš‚æ—¶ä¸å¯ç”¨ï¼ŒHTTPçŠ¶æ€ç : {0}',
                'search_timeout_error': 'æœç´¢è¶…æ—¶ï¼Œè¯·ç¨åé‡è¯•',
                'network_connection_error': 'ç½‘ç»œè¿æ¥å¼‚å¸¸ï¼Œè¯·æ£€æŸ¥ç½‘ç»œåé‡è¯•',
                'search_service_temporarily_unavailable': 'æœç´¢æœåŠ¡æš‚æ—¶ä¸å¯ç”¨ï¼Œè¯·ç¨åé‡è¯•',
                'search_unknown_error_format': 'æœç´¢è¿‡ç¨‹ä¸­å‘ç”ŸæœªçŸ¥é”™è¯¯: {0}',
                'search_results_parse_failed': 'æœç´¢ç»“æœè§£æå¤±è´¥ï¼Œè¯·ç¨åé‡è¯•',
                'no_previous_search': 'æ‚¨è¿˜æ²¡æœ‰è¿›è¡Œæœç´¢ï¼Œè¯·å…ˆä½¿ç”¨æœç´¢æŒ‡ä»¤ï¼Œä¾‹å¦‚ï¼š\næœç”µå½±å\nç™¾åº¦ç”µå½±å\nucç”µå½±å\nè¿…é›·ç”µå½±å',
                'next_page_unknown_error': 'å¤„ç†ä¸‹ä¸€é¡µæŒ‡ä»¤æ—¶å‘ç”ŸæœªçŸ¥é”™è¯¯ï¼Œè¯·ç¨åé‡è¯•',
                'previous_page_unknown_error': 'å¤„ç†ä¸Šä¸€é¡µæŒ‡ä»¤æ—¶å‘ç”ŸæœªçŸ¥é”™è¯¯ï¼Œè¯·ç¨åé‡è¯•',
                'transfer_failed': 'âŒ è½¬å­˜å¤±è´¥ï¼š{0}',
                'transfer_service_error': 'âŒ è½¬å­˜æœåŠ¡å¼‚å¸¸ï¼ŒHTTPçŠ¶æ€ç ï¼š{0}',
                'transfer_timeout': 'âŒ è½¬å­˜è¶…æ—¶ï¼Œè¯·ç¨åé‡è¯•',
                'transfer_process_error': 'âŒ è½¬å­˜è¿‡ç¨‹ä¸­å‘ç”Ÿé”™è¯¯ï¼š{0}',
                'show_config_error': 'æ˜¾ç¤ºé…ç½®ä¿¡æ¯æ—¶å‘ç”Ÿé”™è¯¯',
                'unknown_error': 'æœªçŸ¥é”™è¯¯',
                'invalid_page_number': 'âŒ é¡µç è¶…å‡ºèŒƒå›´ï¼Œæ€»é¡µæ•°ä¸º{0}',
                'format_search_error': 'âŒ æ ¼å¼åŒ–æœç´¢ç»“æœå¤±è´¥',
                'resource_title_default': 'æœªçŸ¥æ ‡é¢˜',
                'resource_link_format': '{0}. {1}\né“¾æ¥: `{2}`',
                'resource_title_format': '{0}. {1}',
                'quark_transfer_prompt': 'ğŸ’¡ å›å¤"è½¬å­˜{0}"å¯è½¬å­˜åˆ°å¤¸å…‹ç½‘ç›˜',
                'search_results_header': 'ğŸ” å…±æ‰¾åˆ° {0} ä¸ªç›¸å…³èµ„æºï¼š',
                'search_results_separator': 'â”€' * 20,
                'search_results_footer': 'é“¾æ¥æœ‰æ•ˆæœŸ5åˆ†é’Ÿï¼Œè¿‡æœŸè¯·é‡æœ',
                'search_results_separator_footer': 'â”€' * 20,
                'search_results_page_info': 'ğŸ“„ ç¬¬ {0}/{1} é¡µ',
                'search_results_navigation': 'ğŸ’¡ å›å¤"ä¸Š/ä¸‹"æˆ–"0/1"ç¿»é¡µ',
                'no_resources_found': 'æœªæ‰¾åˆ°ç›¸å…³èµ„æº: {0}\n\nğŸ’¡ æç¤ºï¼šè¯·å°è¯•å…¶ä»–ç½‘ç›˜æœç´¢'
            }
        }

        try:
            if os.path.exists(config_file):
                with open(config_file, 'r', encoding='utf-8') as f:
                    config = yaml.safe_load(f)
                    if config:
                        # åˆå¹¶é¡¶å±‚é…ç½®
                        for key, value in config.items():
                            if key == 'messages' and isinstance(value, dict):
                                # ç‰¹æ®Šå¤„ç†messageså­—å…¸ï¼Œè¿›è¡Œæ·±åº¦åˆå¹¶
                                if 'messages' in default_config:
                                    default_config['messages'].update(value)
                                else:
                                    default_config['messages'] = value
                            else:
                                default_config[key] = value
                        logger.info("é…ç½®æ–‡ä»¶åŠ è½½æˆåŠŸ")
                    else:
                        logger.warning("é…ç½®æ–‡ä»¶ä¸ºç©ºï¼Œä½¿ç”¨é»˜è®¤é…ç½®")
            else:
                logger.warning("é…ç½®æ–‡ä»¶ä¸å­˜åœ¨ï¼Œä½¿ç”¨é»˜è®¤é…ç½®")
                # åˆ›å»ºé»˜è®¤é…ç½®æ–‡ä»¶
                with open(config_file, 'w', encoding='utf-8') as f:
                    yaml.dump(default_config, f,
                              default_flow_style=False, allow_unicode=True)
                logger.info("å·²åˆ›å»ºé»˜è®¤é…ç½®æ–‡ä»¶")
        except Exception as e:
            logger.error(f"åŠ è½½é…ç½®æ–‡ä»¶å¤±è´¥: {str(e)}ï¼Œä½¿ç”¨é»˜è®¤é…ç½®")

        return default_config

    async def initialize(self):
        """æ’ä»¶åˆå§‹åŒ–æ–¹æ³•"""
        logger.info("å¿ƒæ‚¦æœç´¢æ’ä»¶å·²åŠ è½½")
        logger.info(f"åŸºç¡€URL: {self.base_url}")
        logger.info(f"è½¬å­˜åŠŸèƒ½: {'å·²å¯ç”¨' if self.enable_transfer else 'å·²ç¦ç”¨'}")
        if self.api_key:
            logger.info("APIå¯†é’¥: å·²é…ç½®")
        else:
            logger.warning("APIå¯†é’¥: æœªé…ç½®ï¼Œè½¬å­˜åŠŸèƒ½å¯èƒ½æ— æ³•æ­£å¸¸å·¥ä½œ")

    def _get_user_session_key(self, event: AstrMessageEvent) -> str:
        """è·å–ç”¨æˆ·ä¼šè¯çš„å”¯ä¸€æ ‡è¯†ç¬¦ - æŒ‰ç”¨æˆ·éš”ç¦»ä¼šè¯"""
        try:
            # è·å–ç”¨æˆ·ID
            user_id = None
            if hasattr(event, 'message_obj') and event.message_obj:
                if hasattr(event.message_obj, 'sender') and event.message_obj.sender:
                    user_id = event.message_obj.sender.user_id
            
            # å¦‚æœæˆåŠŸè·å–ç”¨æˆ·IDï¼Œç»„åˆç”¨æˆ·IDå’Œç¾¤IDä½œä¸ºä¼šè¯key
            if user_id:
                # ä½¿ç”¨ ç”¨æˆ·ID@ç¾¤ID çš„æ ¼å¼ï¼Œç¡®ä¿æ¯ä¸ªç”¨æˆ·åœ¨æ¯ä¸ªç¾¤éƒ½æœ‰ç‹¬ç«‹ä¼šè¯
                group_id = event.message_obj.group_id if hasattr(event.message_obj, 'group_id') else event.session_id
                return f"{user_id}@{group_id}"
            
            # fallback: å¦‚æœæ— æ³•è·å–ç”¨æˆ·IDï¼Œä½¿ç”¨åŸæ¥çš„é€»è¾‘
            logger.warning("æ— æ³•è·å–ç”¨æˆ·IDï¼Œä½¿ç”¨unified_msg_originä½œä¸ºä¼šè¯key")
            return event.unified_msg_origin
        except Exception as e:
            logger.error(f"è·å–ç”¨æˆ·ä¼šè¯keyæ—¶å‘ç”Ÿé”™è¯¯: {str(e)}")
            return event.unified_msg_origin

    def _format_reply_with_mention(self, event: AstrMessageEvent, message: str) -> str:
        """æ ¼å¼åŒ–å›å¤æ¶ˆæ¯ï¼Œæ·»åŠ @ç”¨æˆ·ï¼ˆQQä½¿ç”¨CQç æ ¼å¼ï¼‰"""
        # æš‚æ—¶ç¦ç”¨@åŠŸèƒ½ï¼Œå› ä¸ºCQç åœ¨æŸäº›æƒ…å†µä¸‹æ˜¾ç¤ºå¼‚å¸¸
        # å¦‚æœéœ€è¦å¯ç”¨ï¼Œå–æ¶ˆä¸‹é¢çš„æ³¨é‡Š
        return message
        
        # try:
        #     # è·å–å‘é€è€…ID
        #     if hasattr(event, 'message_obj') and event.message_obj:
        #         if hasattr(event.message_obj, 'sender') and event.message_obj.sender:
        #             user_id = event.message_obj.sender.user_id
        #             # QQä½¿ç”¨CQç æ ¼å¼ï¼š[CQ:at,qq=ç”¨æˆ·ID]
        #             return f"[CQ:at,qq={user_id}] {message}"
        #     
        #     # å¦‚æœæ— æ³•è·å–ç”¨æˆ·IDï¼Œè¿”å›åŸæ¶ˆæ¯
        #     return message
        # except Exception as e:
        #     logger.error(f"æ ¼å¼åŒ–@ç”¨æˆ·æ¶ˆæ¯æ—¶å‘ç”Ÿé”™è¯¯: {str(e)}")
        #     return message

    def _get_user_id_for_rate_limit(self, event: AstrMessageEvent) -> str:
        """è·å–ç”¨æˆ·IDç”¨äºé™æµ - æŒ‰ç”¨æˆ·é™æµè€Œä¸æ˜¯æŒ‰ç¾¤é™æµ"""
        try:
            # è·å–ç”¨æˆ·ID
            if hasattr(event, 'message_obj') and event.message_obj:
                if hasattr(event.message_obj, 'sender') and event.message_obj.sender:
                    return str(event.message_obj.sender.user_id)
            
            # fallback: ä½¿ç”¨unified_msg_origin
            logger.warning("æ— æ³•è·å–ç”¨æˆ·IDç”¨äºé™æµï¼Œä½¿ç”¨unified_msg_origin")
            return event.unified_msg_origin
        except Exception as e:
            logger.error(f"è·å–ç”¨æˆ·IDç”¨äºé™æµæ—¶å‘ç”Ÿé”™è¯¯: {str(e)}")
            return event.unified_msg_origin

    @filter.regex(r"^æœ(\s+|(?![ç´¢]).)\S+")
    async def search_resource(self, event: AstrMessageEvent, *args, **kwargs):
        """æœç´¢èµ„æºæŒ‡ä»¤ï¼šæœèµ„æºåç§°"""
        try:
            # è·å–ç”¨æˆ·ä¼šè¯keyï¼ˆç”¨äºä¼šè¯éš”ç¦»ï¼‰
            user_session_key = self._get_user_session_key(event)
            
            # è·å–ç”¨æˆ·IDï¼ˆç”¨äºé™æµï¼‰
            user_id_for_limit = self._get_user_id_for_rate_limit(event)
            
            # é™æµæ£€æŸ¥ - æŒ‰ç”¨æˆ·é™æµ
            if not self.rate_limiter.is_allowed(user_id_for_limit):
                wait_time = self.rate_limiter.get_wait_time(user_id_for_limit)
                yield event.plain_result(f"âŒ è¯·æ±‚è¿‡äºé¢‘ç¹ï¼Œè¯·{wait_time}ç§’åå†è¯•")
                return

            # ç²¾ç¡®æå–"æœ"åçš„å…³é”®è¯ï¼ˆæ”¯æŒå¸¦ç©ºæ ¼å’Œä¸å¸¦ç©ºæ ¼çš„æ ¼å¼ï¼‰
            message = event.message_str.strip()
            if message.startswith("æœ"):
                keyword = message[1:].strip()  # å»æ‰"æœ"å‰ç¼€å¹¶å»é™¤ç©ºæ ¼
            else:
                yield event.plain_result(self.messages['search_command_format_error'].format(self.search_commands['æœ']))
                return

            if not keyword:
                yield event.plain_result(self.messages['search_example_format'].format(self.search_commands['æœ'], 'ç”µå½±å'))
                return

            # ç«‹å³å›å¤ç”¨æˆ·ï¼Œå‘ŠçŸ¥æ­£åœ¨æœç´¢
            yield event.plain_result(self._format_reply_with_mention(event, self.messages['searching']))

            # é»˜è®¤ä½¿ç”¨å¤¸å…‹ç½‘ç›˜æœç´¢
            result = await self._search_resources(user_session_key, keyword, is_full_network=False, pan_type=0)
            yield event.plain_result(self._format_reply_with_mention(event, result))
        except Exception as e:
            logger.error(f"æœç´¢èµ„æºæ—¶å‘ç”Ÿé”™è¯¯: {str(e)}")
            yield event.plain_result(self.messages['search_error'])

    @filter.regex(r"^æ‰¾\s*\S+")
    async def local_search(self, event: AstrMessageEvent):
        """æœ¬åœ°æœç´¢æŒ‡ä»¤ï¼šæ‰¾èµ„æºåç§°ï¼ˆåªæŸ¥è¯¢æœ¬åœ°æ•°æ®åº“ï¼‰"""
        try:
            # è·å–ç”¨æˆ·ä¼šè¯keyï¼ˆç”¨äºä¼šè¯éš”ç¦»ï¼‰
            user_session_key = self._get_user_session_key(event)
            
            # è·å–ç”¨æˆ·IDï¼ˆç”¨äºé™æµï¼‰
            user_id_for_limit = self._get_user_id_for_rate_limit(event)
            
            # é™æµæ£€æŸ¥ - æŒ‰ç”¨æˆ·é™æµ
            if not self.rate_limiter.is_allowed(user_id_for_limit):
                wait_time = self.rate_limiter.get_wait_time(user_id_for_limit)
                yield event.plain_result(f"âŒ è¯·æ±‚è¿‡äºé¢‘ç¹ï¼Œè¯·{wait_time}ç§’åå†è¯•")
                return

            # æå–"æ‰¾"åçš„å…³é”®è¯
            message = event.message_str.strip()
            if message.startswith("æ‰¾"):
                keyword = message[1:].strip()
            else:
                yield event.plain_result("æŒ‡ä»¤æ ¼å¼é”™è¯¯ï¼Œè¯·ä½¿ç”¨ï¼šæ‰¾èµ„æºåç§°")
                return

            if not keyword:
                yield event.plain_result("è¯·è¾“å…¥è¦æŸ¥æ‰¾çš„èµ„æºåç§°ï¼Œä¾‹å¦‚ï¼šæ‰¾ç”µå½±å")
                return

            # ç«‹å³å›å¤ç”¨æˆ·
            yield event.plain_result(self._format_reply_with_mention(event, "ğŸ” æ­£åœ¨æœ¬åœ°æ•°æ®åº“æŸ¥æ‰¾ï¼Œè¯·ç¨å€™..."))

            # è°ƒç”¨æœ¬åœ°æœç´¢
            result = await self._local_search(keyword)
            yield event.plain_result(self._format_reply_with_mention(event, result))
            
        except Exception as e:
            logger.error(f"æœ¬åœ°æœç´¢æ—¶å‘ç”Ÿé”™è¯¯: {str(e)}")
            yield event.plain_result("âŒ æœç´¢è¿‡ç¨‹ä¸­å‘ç”Ÿé”™è¯¯ï¼Œè¯·ç¨åé‡è¯•")

    @filter.regex(r"^ç™¾åº¦\s*\S+")
    async def baidu_search(self, event: AstrMessageEvent):
        """ç™¾åº¦æœç´¢æŒ‡ä»¤ï¼šç™¾åº¦èµ„æºåç§°"""
        try:
            # è·å–ç”¨æˆ·ä¼šè¯keyï¼ˆç”¨äºä¼šè¯éš”ç¦»ï¼‰
            user_session_key = self._get_user_session_key(event)
            
            # è·å–ç”¨æˆ·IDï¼ˆç”¨äºé™æµï¼‰
            user_id_for_limit = self._get_user_id_for_rate_limit(event)
            
            # é™æµæ£€æŸ¥ - æŒ‰ç”¨æˆ·é™æµ
            if not self.rate_limiter.is_allowed(user_id_for_limit):
                wait_time = self.rate_limiter.get_wait_time(user_id_for_limit)
                yield event.plain_result(f"âŒ è¯·æ±‚è¿‡äºé¢‘ç¹ï¼Œè¯·{wait_time}ç§’åå†è¯•")
                return

            # ç²¾ç¡®æå–"ç™¾åº¦"åçš„å…³é”®è¯ï¼ˆæ”¯æŒå¸¦ç©ºæ ¼å’Œä¸å¸¦ç©ºæ ¼çš„æ ¼å¼ï¼‰
            message = event.message_str.strip()
            if message.startswith("ç™¾åº¦"):
                keyword = message[2:].strip()  # å»æ‰"ç™¾åº¦"å‰ç¼€å¹¶å»é™¤ç©ºæ ¼
            else:
                yield event.plain_result(self.messages['baidu_format_error'])
                return

            if not keyword:
                yield event.plain_result(self.messages['baidu_example'].format('ç”µå½±å'))
                return

            # ç«‹å³å›å¤ç”¨æˆ·ï¼Œå‘ŠçŸ¥æ­£åœ¨æœç´¢
            yield event.plain_result(self._format_reply_with_mention(event, self.messages['searching']))

            # ä½¿ç”¨ç™¾åº¦ç½‘ç›˜æœç´¢
            result = await self._search_resources(user_session_key, keyword, is_full_network=False, pan_type=2)
            yield event.plain_result(self._format_reply_with_mention(event, result))
        except Exception as e:
            logger.error(f"ç™¾åº¦æœç´¢æ—¶å‘ç”Ÿé”™è¯¯: {str(e)}")
            yield event.plain_result(self.messages['search_error'])

    @filter.regex(r"^uc\s*\S+")
    async def uc_search_lower(self, event: AstrMessageEvent):
        """UCæœç´¢æŒ‡ä»¤ï¼šucèµ„æºåç§°"""
        try:
            # è·å–ç”¨æˆ·ä¼šè¯keyï¼ˆç”¨äºä¼šè¯éš”ç¦»ï¼‰
            user_session_key = self._get_user_session_key(event)
            
            # è·å–ç”¨æˆ·IDï¼ˆç”¨äºé™æµï¼‰
            user_id_for_limit = self._get_user_id_for_rate_limit(event)
            
            # é™æµæ£€æŸ¥ - æŒ‰ç”¨æˆ·é™æµ
            if not self.rate_limiter.is_allowed(user_id_for_limit):
                wait_time = self.rate_limiter.get_wait_time(user_id_for_limit)
                yield event.plain_result(f"âŒ è¯·æ±‚è¿‡äºé¢‘ç¹ï¼Œè¯·{wait_time}ç§’åå†è¯•")
                return

            # ç²¾ç¡®æå–"uc"åçš„å…³é”®è¯ï¼ˆæ”¯æŒå¸¦ç©ºæ ¼å’Œä¸å¸¦ç©ºæ ¼çš„æ ¼å¼ï¼‰
            message = event.message_str.strip()
            if message.startswith("uc"):
                keyword = message[2:].strip()  # å»æ‰"uc"å‰ç¼€å¹¶å»é™¤ç©ºæ ¼
            else:
                yield event.plain_result(self.messages['uc_format_error'])
                return

            if not keyword:
                yield event.plain_result(self.messages['uc_example'].format('ç”µå½±å'))
                return

            # ç«‹å³å›å¤ç”¨æˆ·ï¼Œå‘ŠçŸ¥æ­£åœ¨æœç´¢
            yield event.plain_result(self._format_reply_with_mention(event, self.messages['searching']))

            # ä½¿ç”¨UCç½‘ç›˜æœç´¢
            result = await self._search_resources(user_session_key, keyword, is_full_network=False, pan_type=3)
            yield event.plain_result(self._format_reply_with_mention(event, result))
        except Exception as e:
            logger.error(f"UCæœç´¢æ—¶å‘ç”Ÿé”™è¯¯: {str(e)}")
            yield event.plain_result(self.messages['search_error'])

    @filter.regex(r"^UC\s*\S+")
    async def uc_search_upper(self, event: AstrMessageEvent):
        """UCæœç´¢æŒ‡ä»¤ï¼šUCèµ„æºåç§°"""
        try:
            # è·å–ç”¨æˆ·ä¼šè¯keyï¼ˆç”¨äºä¼šè¯éš”ç¦»ï¼‰
            user_session_key = self._get_user_session_key(event)
            
            # è·å–ç”¨æˆ·IDï¼ˆç”¨äºé™æµï¼‰
            user_id_for_limit = self._get_user_id_for_rate_limit(event)
            
            # é™æµæ£€æŸ¥ - æŒ‰ç”¨æˆ·é™æµ
            if not self.rate_limiter.is_allowed(user_id_for_limit):
                wait_time = self.rate_limiter.get_wait_time(user_id_for_limit)
                yield event.plain_result(f"âŒ è¯·æ±‚è¿‡äºé¢‘ç¹ï¼Œè¯·{wait_time}ç§’åå†è¯•")
                return

            # ç²¾ç¡®æå–"UC"åçš„å…³é”®è¯ï¼ˆæ”¯æŒå¸¦ç©ºæ ¼å’Œä¸å¸¦ç©ºæ ¼çš„æ ¼å¼ï¼‰
            message = event.message_str.strip()
            if message.startswith("UC"):
                keyword = message[2:].strip()  # å»æ‰"UC"å‰ç¼€å¹¶å»é™¤ç©ºæ ¼
            else:
                yield event.plain_result(self.messages['uc_upper_format_error'])
                return

            if not keyword:
                yield event.plain_result(self.messages['uc_upper_example'].format('ç”µå½±å'))
                return

            # ç«‹å³å›å¤ç”¨æˆ·ï¼Œå‘ŠçŸ¥æ­£åœ¨æœç´¢
            yield event.plain_result(self._format_reply_with_mention(event, self.messages['searching']))

            # ä½¿ç”¨UCç½‘ç›˜æœç´¢
            result = await self._search_resources(user_session_key, keyword, is_full_network=False, pan_type=3)
            yield event.plain_result(self._format_reply_with_mention(event, result))
        except Exception as e:
            logger.error(f"UCæœç´¢æ—¶å‘ç”Ÿé”™è¯¯: {str(e)}")
            yield event.plain_result(self.messages['search_error'])

    @filter.regex(r"^è¿…é›·\s*\S+")
    async def xunlei_search(self, event: AstrMessageEvent):
        """è¿…é›·æœç´¢æŒ‡ä»¤ï¼šè¿…é›·èµ„æºåç§°"""
        try:
            # è·å–ç”¨æˆ·ä¼šè¯keyï¼ˆç”¨äºä¼šè¯éš”ç¦»ï¼‰
            user_session_key = self._get_user_session_key(event)
            
            # è·å–ç”¨æˆ·IDï¼ˆç”¨äºé™æµï¼‰
            user_id_for_limit = self._get_user_id_for_rate_limit(event)
            
            # é™æµæ£€æŸ¥ - æŒ‰ç”¨æˆ·é™æµ
            if not self.rate_limiter.is_allowed(user_id_for_limit):
                wait_time = self.rate_limiter.get_wait_time(user_id_for_limit)
                yield event.plain_result(f"âŒ è¯·æ±‚è¿‡äºé¢‘ç¹ï¼Œè¯·{wait_time}ç§’åå†è¯•")
                return

            # ç²¾ç¡®æå–"è¿…é›·"åçš„å…³é”®è¯ï¼ˆæ”¯æŒå¸¦ç©ºæ ¼å’Œä¸å¸¦ç©ºæ ¼çš„æ ¼å¼ï¼‰
            message = event.message_str.strip()
            if message.startswith("è¿…é›·"):
                keyword = message[2:].strip()  # å»æ‰"è¿…é›·"å‰ç¼€å¹¶å»é™¤ç©ºæ ¼
            else:
                yield event.plain_result(self.messages['xunlei_format_error'])
                return

            if not keyword:
                yield event.plain_result(self.messages['xunlei_example'].format('ç”µå½±å'))
                return

            # ç«‹å³å›å¤ç”¨æˆ·ï¼Œå‘ŠçŸ¥æ­£åœ¨æœç´¢
            yield event.plain_result(self._format_reply_with_mention(event, self.messages['searching']))

            # ä½¿ç”¨è¿…é›·ç½‘ç›˜æœç´¢
            result = await self._search_resources(user_session_key, keyword, is_full_network=False, pan_type=4)
            yield event.plain_result(self._format_reply_with_mention(event, result))
        except Exception as e:
            logger.error(f"è¿…é›·æœç´¢æ—¶å‘ç”Ÿé”™è¯¯: {str(e)}")
            yield event.plain_result(self.messages['search_error'])

    @filter.regex(r"^1$")
    async def next_page(self, event: AstrMessageEvent):
        """å¤„ç†ä¸‹ä¸€é¡µæŒ‡ä»¤ï¼ˆç”¨æˆ·è¾“å…¥'1'ï¼‰"""
        try:
            # æ£€æŸ¥åˆ†é¡µåŠŸèƒ½æ˜¯å¦å¯ç”¨
            if not self.enable_pagination:
                return
            
            # è·å–ç”¨æˆ·ä¼šè¯key
            user_session_key = self._get_user_session_key(event)

            # æ£€æŸ¥ç”¨æˆ·æ˜¯å¦æœ‰æœªå®Œæˆçš„æœç´¢ä¼šè¯
            if user_session_key in self.user_sessions and 'results' in self.user_sessions[user_session_key]:
                session_data = self.user_sessions[user_session_key]
                
                # æ£€æŸ¥æ˜¯å¦æœ‰æœ‰æ•ˆçš„æœç´¢ç»“æœ
                results = session_data.get('results')
                if not results:
                    # æ²¡æœ‰æœç´¢ç»“æœï¼Œä¸å“åº”ç¿»é¡µ
                    return
                
                current_page = session_data.get('current_page', 1)
                total_pages = session_data.get('total_pages', 1)
                
                # å¦‚æœæ€»é¡µæ•°ä¸º0æˆ–1ï¼Œè¯´æ˜æ²¡æœ‰è¶³å¤Ÿçš„ç»“æœéœ€è¦ç¿»é¡µ
                if total_pages <= 1:
                    return
                
                keyword = session_data.get('keyword', '')
                is_full_network = session_data.get('is_full_network', False)
                pan_type = session_data.get('pan_type', 0)

                # æ£€æŸ¥æ˜¯å¦è¿˜æœ‰ä¸‹ä¸€é¡µ
                if current_page < total_pages:
                    # ç«‹å³å›å¤ç”¨æˆ·ï¼Œå‘ŠçŸ¥æ­£åœ¨ç¿»é¡µ
                    yield event.plain_result(self._format_reply_with_mention(event, "â³ æ­£åœ¨ç¿»é¡µï¼Œè¯·ç¨å€™..."))
                    
                    # æ›´æ–°é¡µç 
                    next_page = current_page + 1
                    self.user_sessions[user_session_key]['current_page'] = next_page

                    # æ ¼å¼åŒ–å¹¶è¿”å›ä¸‹ä¸€é¡µç»“æœ
                    result = await self._format_search_results(user_session_key, results, keyword, is_full_network, next_page)
                    yield event.plain_result(self._format_reply_with_mention(event, result))
                else:
                    yield event.plain_result(self._format_reply_with_mention(event, self.messages['last_page']))
            # å¦‚æœæ²¡æœ‰æœç´¢ä¼šè¯ï¼Œä¸å“åº”ï¼ˆé¿å…è¯¯è§¦å‘ï¼‰
        except Exception as e:
            logger.error(f"å¤„ç†ä¸‹ä¸€é¡µæŒ‡ä»¤æ—¶å‘ç”Ÿé”™è¯¯: {str(e)}")
            yield event.plain_result(self.messages['next_page_error'])

    @filter.regex(r"^0$")
    async def previous_page(self, event: AstrMessageEvent):
        """å¤„ç†ä¸Šä¸€é¡µæŒ‡ä»¤ï¼ˆç”¨æˆ·è¾“å…¥'0'ï¼‰"""
        try:
            # æ£€æŸ¥åˆ†é¡µåŠŸèƒ½æ˜¯å¦å¯ç”¨
            if not self.enable_pagination:
                return
            
            # è·å–ç”¨æˆ·ä¼šè¯key
            user_session_key = self._get_user_session_key(event)

            # æ£€æŸ¥ç”¨æˆ·æ˜¯å¦æœ‰æœªå®Œæˆçš„æœç´¢ä¼šè¯
            if user_session_key in self.user_sessions and 'results' in self.user_sessions[user_session_key]:
                session_data = self.user_sessions[user_session_key]
                
                # æ£€æŸ¥æ˜¯å¦æœ‰æœ‰æ•ˆçš„æœç´¢ç»“æœ
                results = session_data.get('results')
                if not results:
                    return
                
                current_page = session_data.get('current_page', 1)
                total_pages = session_data.get('total_pages', 1)
                
                # å¦‚æœæ€»é¡µæ•°ä¸º0æˆ–1ï¼Œè¯´æ˜æ²¡æœ‰è¶³å¤Ÿçš„ç»“æœéœ€è¦ç¿»é¡µ
                if total_pages <= 1:
                    return
                
                keyword = session_data.get('keyword', '')
                is_full_network = session_data.get('is_full_network', False)
                pan_type = session_data.get('pan_type', 0)

                # æ£€æŸ¥æ˜¯å¦è¿˜æœ‰ä¸Šä¸€é¡µ
                if current_page > 1:
                    # ç«‹å³å›å¤ç”¨æˆ·ï¼Œå‘ŠçŸ¥æ­£åœ¨ç¿»é¡µ
                    yield event.plain_result(self._format_reply_with_mention(event, "â³ æ­£åœ¨ç¿»é¡µï¼Œè¯·ç¨å€™..."))
                    
                    # æ›´æ–°é¡µç 
                    previous_page = current_page - 1
                    self.user_sessions[user_session_key]['current_page'] = previous_page

                    # æ ¼å¼åŒ–å¹¶è¿”å›ä¸Šä¸€é¡µç»“æœ
                    result = await self._format_search_results(user_session_key, results, keyword, is_full_network, previous_page)
                    yield event.plain_result(self._format_reply_with_mention(event, result))
                else:
                    yield event.plain_result(self._format_reply_with_mention(event, self.messages['first_page']))
            # å¦‚æœæ²¡æœ‰æœç´¢ä¼šè¯ï¼Œä¸å“åº”
        except Exception as e:
            logger.error(f"å¤„ç†ä¸Šä¸€é¡µæŒ‡ä»¤æ—¶å‘ç”Ÿé”™è¯¯: {str(e)}")
            yield event.plain_result(self.messages['previous_page_error'])

    @filter.regex(r"^ä¸‹$")
    async def next_page_simple(self, event: AstrMessageEvent):
        """å¤„ç†ç®€å•ä¸‹ä¸€é¡µæŒ‡ä»¤ï¼ˆç”¨æˆ·è¾“å…¥'ä¸‹'ï¼‰"""
        try:
            # æ£€æŸ¥åˆ†é¡µåŠŸèƒ½æ˜¯å¦å¯ç”¨
            if not self.enable_pagination:
                return
            
            # è·å–ç”¨æˆ·ä¼šè¯key
            user_session_key = self._get_user_session_key(event)

            # æ£€æŸ¥ç”¨æˆ·æ˜¯å¦æœ‰æœªå®Œæˆçš„æœç´¢ä¼šè¯
            if user_session_key in self.user_sessions and 'results' in self.user_sessions[user_session_key]:
                session_data = self.user_sessions[user_session_key]
                
                # æ£€æŸ¥æ˜¯å¦æœ‰æœ‰æ•ˆçš„æœç´¢ç»“æœ
                results = session_data.get('results')
                if not results:
                    return
                
                current_page = session_data.get('current_page', 1)
                total_pages = session_data.get('total_pages', 1)
                
                # å¦‚æœæ€»é¡µæ•°ä¸º0æˆ–1ï¼Œè¯´æ˜æ²¡æœ‰è¶³å¤Ÿçš„ç»“æœéœ€è¦ç¿»é¡µ
                if total_pages <= 1:
                    return
                
                keyword = session_data.get('keyword', '')
                is_full_network = session_data.get('is_full_network', False)
                pan_type = session_data.get('pan_type', 0)

                # æ£€æŸ¥æ˜¯å¦è¿˜æœ‰ä¸‹ä¸€é¡µ
                if current_page < total_pages:
                    # ç«‹å³å›å¤ç”¨æˆ·ï¼Œå‘ŠçŸ¥æ­£åœ¨ç¿»é¡µ
                    yield event.plain_result(self._format_reply_with_mention(event, "â³ æ­£åœ¨ç¿»é¡µï¼Œè¯·ç¨å€™..."))
                    
                    # æ›´æ–°é¡µç 
                    next_page = current_page + 1
                    self.user_sessions[user_session_key]['current_page'] = next_page

                    # æ ¼å¼åŒ–å¹¶è¿”å›ä¸‹ä¸€é¡µç»“æœ
                    result = await self._format_search_results(user_session_key, results, keyword, is_full_network, next_page)
                    yield event.plain_result(self._format_reply_with_mention(event, result))
                else:
                    yield event.plain_result(self._format_reply_with_mention(event, self.messages['last_page']))
            # å¦‚æœæ²¡æœ‰æœç´¢ä¼šè¯ï¼Œä¸å“åº”
        except Exception as e:
            logger.error(f"å¤„ç†ä¸‹ä¸€é¡µæŒ‡ä»¤æ—¶å‘ç”Ÿé”™è¯¯: {str(e)}")
            yield event.plain_result(self.messages['next_page_error'])

    @filter.regex(r"^ä¸Š$")
    async def previous_page_simple(self, event: AstrMessageEvent):
        """å¤„ç†ç®€å•ä¸Šä¸€é¡µæŒ‡ä»¤ï¼ˆç”¨æˆ·è¾“å…¥'ä¸Š'ï¼‰"""
        try:
            # æ£€æŸ¥åˆ†é¡µåŠŸèƒ½æ˜¯å¦å¯ç”¨
            if not self.enable_pagination:
                return
            
            # è·å–ç”¨æˆ·ä¼šè¯key
            user_session_key = self._get_user_session_key(event)

            # æ£€æŸ¥ç”¨æˆ·æ˜¯å¦æœ‰æœªå®Œæˆçš„æœç´¢ä¼šè¯
            if user_session_key in self.user_sessions and 'results' in self.user_sessions[user_session_key]:
                session_data = self.user_sessions[user_session_key]
                
                # æ£€æŸ¥æ˜¯å¦æœ‰æœ‰æ•ˆçš„æœç´¢ç»“æœ
                results = session_data.get('results')
                if not results:
                    return
                
                current_page = session_data.get('current_page', 1)
                total_pages = session_data.get('total_pages', 1)
                
                # å¦‚æœæ€»é¡µæ•°ä¸º0æˆ–1ï¼Œè¯´æ˜æ²¡æœ‰è¶³å¤Ÿçš„ç»“æœéœ€è¦ç¿»é¡µ
                if total_pages <= 1:
                    return
                
                keyword = session_data.get('keyword', '')
                is_full_network = session_data.get('is_full_network', False)
                pan_type = session_data.get('pan_type', 0)

                # æ£€æŸ¥æ˜¯å¦è¿˜æœ‰ä¸Šä¸€é¡µ
                if current_page > 1:
                    # ç«‹å³å›å¤ç”¨æˆ·ï¼Œå‘ŠçŸ¥æ­£åœ¨ç¿»é¡µ
                    yield event.plain_result(self._format_reply_with_mention(event, "â³ æ­£åœ¨ç¿»é¡µï¼Œè¯·ç¨å€™..."))
                    
                    # æ›´æ–°é¡µç 
                    previous_page = current_page - 1
                    self.user_sessions[user_session_key]['current_page'] = previous_page

                    # æ ¼å¼åŒ–å¹¶è¿”å›ä¸Šä¸€é¡µç»“æœ
                    result = await self._format_search_results(user_session_key, results, keyword, is_full_network, previous_page)
                    yield event.plain_result(self._format_reply_with_mention(event, result))
                else:
                    yield event.plain_result(self._format_reply_with_mention(event, self.messages['first_page']))
            else:
                yield event.plain_result(self.messages['no_search_session'])
        except Exception as e:
            logger.error(f"å¤„ç†ä¸Šä¸€é¡µæŒ‡ä»¤æ—¶å‘ç”Ÿé”™è¯¯: {str(e)}")
            yield event.plain_result(self.messages['previous_page_error'])

    @filter.regex(r"^è½¬å­˜(\d+)$")
    async def transfer_resource(self, event: AstrMessageEvent):
        """å¤„ç†è½¬å­˜æŒ‡ä»¤ï¼Œä¾‹å¦‚ï¼šè½¬å­˜1"""
        try:
            # æ£€æŸ¥è½¬å­˜åŠŸèƒ½æ˜¯å¦å¯ç”¨
            if not self.enable_transfer:
                yield event.plain_result(self.messages['transfer_disabled'])
                return

            # æ£€æŸ¥APIå¯†é’¥
            if not self.api_key:
                yield event.plain_result(self.messages['api_key_required'])
                return

            # è·å–ç”¨æˆ·ä¼šè¯key
            user_session_key = self._get_user_session_key(event)

            # æå–è¦è½¬å­˜çš„èµ„æºç¼–å·
            match = re.search(r"è½¬å­˜(\d+)", event.get_message_content())
            if not match:
                yield event.plain_result(self.messages['invalid_transfer_command'])
                return

            resource_index = int(match.group(1))

            # æ£€æŸ¥ç”¨æˆ·æ˜¯å¦æœ‰æœªå®Œæˆçš„æœç´¢ä¼šè¯
            if user_session_key not in self.user_sessions or 'results' not in self.user_sessions[user_session_key]:
                yield event.plain_result(self.messages['no_search_for_transfer'])
                return

            session_data = self.user_sessions[user_session_key]
            current_page = session_data.get('current_page', 1)
            results = session_data['results']

            # è§£ææœç´¢ç»“æœæ•°æ®
            result_list = []
            if isinstance(results, str) and session_data.get('is_sse', False):
                # SSEå“åº”ï¼Œéœ€è¦é‡æ–°è§£æ
                parsed_data = self._parse_sse_response(
                    results, session_data.get('keyword', ''), current_page)
                if isinstance(parsed_data, list):
                    result_list = parsed_data
            elif isinstance(results, dict):
                # JSONå“åº”ï¼Œæå–æ•°æ®
                if 'result' in results:
                    result_list = results['result']
                elif 'data' in results:
                    result_list = results['data']
                elif 'list' in results:
                    result_list = results['list']
            elif isinstance(results, list):
                result_list = results

            if not result_list:
                yield event.plain_result(self.messages['search_expired'])
                return

            # è®¡ç®—å½“å‰é¡µçš„èµ·å§‹ç´¢å¼•
            page_size = 5
            start_index = (current_page - 1) * page_size

            # æ£€æŸ¥èµ„æºç¼–å·æ˜¯å¦æœ‰æ•ˆ
            if resource_index < 1 or resource_index > len(result_list):
                yield event.plain_result(self.messages['invalid_resource_index'].format(len(result_list)))
                return

            # è·å–å¯¹åº”çš„èµ„æº
            target_resource = result_list[start_index + resource_index - 1]
            url = target_resource.get('url', '')
            title = target_resource.get('title', 'æœªçŸ¥æ ‡é¢˜')

            if not url:
                yield event.plain_result(self.messages['no_valid_link'])
                return

            # æ£€æŸ¥æ˜¯å¦ä¸ºå¤¸å…‹ç½‘ç›˜é“¾æ¥
            # ç§»é™¤åªæ”¯æŒå¤¸å…‹ç½‘ç›˜çš„é™åˆ¶ï¼Œæ”¯æŒæ‰€æœ‰å¿ƒæ‚¦ç³»ç»Ÿæ”¯æŒçš„ç½‘ç›˜
            supported_domains = ['pan.quark.cn', 'www.alipan.com', 'www.aliyundrive.com',
                                 'pan.baidu.com', 'drive.uc.cn', 'fast.uc.cn', 'pan.xunlei.com']
            is_supported = False
            # è½¬æ¢URLä¸ºå°å†™ä»¥å¤„ç†å¤§å°å†™ä¸ä¸€è‡´çš„æƒ…å†µ
            lower_url = url.lower()
            for domain in supported_domains:
                if domain in lower_url:
                    is_supported = True
                    break

            if not is_supported:
                yield event.plain_result("âŒ æš‚ä¸æ”¯æŒè¯¥ç½‘ç›˜çš„è½¬å­˜åŠŸèƒ½")
                return

            # å‘é€è½¬å­˜ä¸­æç¤º
            yield event.plain_result(self.messages['transferring'].format(title))

            # æ·»åŠ å»¶è¿Ÿé¿å…è¯·æ±‚è¿‡äºé¢‘ç¹
            await asyncio.sleep(self.transfer_delay)

            # è°ƒç”¨è½¬å­˜API
            transfer_result = await self._transfer_and_share(url, "")
            if transfer_result['success']:
                result = f"âœ… è½¬å­˜æˆåŠŸ\nèµ„æºæ ‡é¢˜ï¼š{transfer_result['title']}\nåˆ†äº«é“¾æ¥ï¼š{transfer_result['share_url']}"
            else:
                result = f"âŒ è½¬å­˜å¤±è´¥\n{transfer_result.get('error', 'æœªçŸ¥é”™è¯¯')}"
            yield event.plain_result(result)

        except Exception as e:
            logger.error(f"å¤„ç†è½¬å­˜æŒ‡ä»¤æ—¶å‘ç”Ÿé”™è¯¯: {str(e)}")
            yield event.plain_result(self.messages['transfer_error'])

    async def _search_resources(self, user_session_key: str, keyword: str, is_full_network: bool = False, pan_type: int = 0, page: int = 1) -> str:
        """æœç´¢èµ„æºçš„æ ¸å¿ƒæ–¹æ³•"""
        # è¾“å…¥éªŒè¯
        if not keyword or not keyword.strip():
            return self.messages['empty_keyword']

        # å…³é”®è¯é•¿åº¦é™åˆ¶
        if len(keyword) > 50:
            return self.messages['keyword_too_long']

        retry_count = 0
        while retry_count < self.max_retries:
            try:
                # æ„å»ºæœç´¢URL
                if is_full_network:
                    # å…¨ç½‘æœç´¢API
                    url = f"{self.base_url}/api/other/all_search"
                    params = {
                        "title": keyword
                    }
                else:
                    # æ™®é€šæœç´¢API
                    url = f"{self.base_url}/api/other/web_search"
                    params = {
                        "title": keyword,
                        "is_type": pan_type,  # ç½‘ç›˜ç±»å‹
                        "is_show": 1  # æ˜¾ç¤ºç½‘å€
                    }

                # è®¾ç½®è¯·æ±‚å¤´ï¼Œæ¨¡æ‹Ÿæµè§ˆå™¨è®¿é—®å¹¶æ·»åŠ APIè®¤è¯
                headers = {
                    'User-Agent': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/131.0.0.0 Safari/537.36',
                    'Accept': 'text/event-stream',
                    'Accept-Language': 'zh-CN,zh;q=0.9,en;q=0.8',
                    'Referer': f'{self.base_url}/',
                    'Origin': self.base_url
                }
                
                # å¦‚æœé…ç½®äº†APIå¯†é’¥ï¼Œæ·»åŠ åˆ°è¯·æ±‚å¤´
                if self.api_key:
                    headers['Authorization'] = f'Bearer {self.api_key}'

                # å‘èµ·HTTPè¯·æ±‚
                async with aiohttp.ClientSession() as session:
                    async with session.get(url, params=params, headers=headers, timeout=aiohttp.ClientTimeout(total=self.search_timeout)) as response:
                        if response.status == 200:
                            # è§£æå“åº”
                            try:
                                # æ£€æŸ¥å“åº”å†…å®¹ç±»å‹
                                content_type = response.headers.get('content-type', '')
                                if 'text/event-stream' in content_type:
                                    # å¤„ç†SSEæµå¼å“åº”
                                    text = await response.text()
                                    # è§£æSSEå“åº”
                                    parsed_data = self._parse_sse_response(text, keyword, page)
                                    # ä¿å­˜æœç´¢ç»“æœåˆ°ç”¨æˆ·ä¼šè¯ï¼ˆç”¨äºåˆ†é¡µï¼‰
                                    self.user_sessions[user_session_key] = {
                                        'results': text,  # ä¿å­˜åŸå§‹SSEå“åº”æ–‡æœ¬
                                        'keyword': keyword,
                                        'is_full_network': is_full_network,
                                        'pan_type': pan_type,
                                        'current_page': page,
                                        'total_pages': 1,  # é»˜è®¤å€¼ï¼Œä¼šåœ¨_format_search_resultsä¸­æ›´æ–°
                                        'is_sse': True  # æ ‡è®°ä¸ºSSEå“åº”
                                    }
                                    # æ ¼å¼åŒ–ç»“æœå¹¶è¿”å›
                                    return await self._format_search_results(user_session_key, parsed_data, keyword, is_full_network, page)
                                else:
                                    # å¤„ç†æ ‡å‡†JSONå“åº”
                                    data = await response.json()
                                    # ä¿å­˜æœç´¢ç»“æœåˆ°ç”¨æˆ·ä¼šè¯ï¼ˆç”¨äºåˆ†é¡µï¼‰
                                    self.user_sessions[user_session_key] = {
                                        'results': data,
                                        'keyword': keyword,
                                        'is_full_network': is_full_network,
                                        'pan_type': pan_type,
                                        'current_page': page,
                                        'total_pages': 1,  # é»˜è®¤å€¼ï¼Œä¼šåœ¨_format_search_resultsä¸­æ›´æ–°
                                        'is_sse': False  # æ ‡è®°ä¸ºJSONå“åº”
                                    }
                                    return await self._format_search_results(user_session_key, data, keyword, is_full_network, page)
                            except Exception as e:
                                logger.error(
                                    f"è§£æå“åº”å¤±è´¥: {str(e)}, status={response.status}, content-type={content_type}")
                                return self.messages['parse_search_failed']
                        elif response.status == 404:
                            return self.messages['no_resources_found'].format(keyword)
                        elif response.status == 429:
                            retry_count += 1
                            if retry_count >= self.max_retries:
                                return self.messages['too_many_requests']
                            await asyncio.sleep(2 ** retry_count)  # æŒ‡æ•°é€€é¿
                            continue
                        else:
                            retry_count += 1
                            if retry_count >= self.max_retries:
                                return self.messages['search_service_unavailable'].format(response.status)
                            await asyncio.sleep(1)
                            continue

            except asyncio.TimeoutError:
                retry_count += 1
                if retry_count >= self.max_retries:
                    return self.messages['search_timeout']
                await asyncio.sleep(2 ** retry_count)  # æŒ‡æ•°é€€é¿
                continue
            except aiohttp.ClientError as e:
                retry_count += 1
                if retry_count >= self.max_retries:
                    logger.error(f"ç½‘ç»œè¯·æ±‚é”™è¯¯: {str(e)}")
                    return self.messages['network_error']
                await asyncio.sleep(2 ** retry_count)
                continue
            except Exception as e:
                logger.error(f"æœç´¢è¿‡ç¨‹ä¸­å‘ç”ŸæœªçŸ¥é”™è¯¯: {str(e)}")
                return self.messages['unknown_search_error'].format(str(e))

        return self.messages['search_service_unavailable_temporarily']

    async def _local_search(self, keyword: str) -> str:
        """æœ¬åœ°æ•°æ®åº“æœç´¢ï¼ˆåªæŸ¥è¯¢æ•°æ®åº“ï¼Œä¸æ‰§è¡Œå…¨ç½‘æœç´¢ï¼‰"""
        try:
            # ä½¿ç”¨ /api/search/index æ¥å£æŸ¥è¯¢æœ¬åœ°æ•°æ®åº“
            # è¯¥æ¥å£é»˜è®¤æŸ¥è¯¢ is_time=0 çš„æ°¸ä¹…èµ„æºï¼Œä¸ä¼šè§¦å‘å…¨ç½‘æœç´¢
            url = f"{self.base_url}/api/search/index"
            params = {
                "title": keyword,
                "page": 1,
                "page_size": 10
            }
            
            logger.info(f"æ­£åœ¨æœ¬åœ°æ•°æ®åº“æŸ¥æ‰¾: {keyword}")
            
            # è®¾ç½®è¾ƒçŸ­çš„è¶…æ—¶æ—¶é—´ï¼ˆ5ç§’ï¼‰ï¼Œæœ¬åœ°æ•°æ®åº“æŸ¥è¯¢åº”è¯¥å¾ˆå¿«
            async with aiohttp.ClientSession() as session:
                async with session.get(url, params=params, timeout=aiohttp.ClientTimeout(total=5)) as response:
                    if response.status == 200:
                        data = await response.json()
                        
                        # æ£€æŸ¥è¿”å›æ•°æ®
                        if data.get('code') == 200 and data.get('data'):
                            result_data = data['data']
                            # getListè¿”å›çš„æ•°æ®ç»“æ„ï¼š{total_result: ..., items: [...]}
                            if isinstance(result_data, dict) and 'items' in result_data:
                                results = result_data['items']
                            elif isinstance(result_data, dict) and 'list' in result_data:
                                results = result_data['list']
                            elif isinstance(result_data, list):
                                results = result_data
                            else:
                                results = []
                            
                            if len(results) == 0:
                                return f"âŒ æœ¬åœ°æ•°æ®åº“æœªæ‰¾åˆ°ç›¸å…³èµ„æº: {keyword}\n\nğŸ’¡ æç¤ºï¼šå¯ä»¥å°è¯•ä½¿ç”¨ã€æœ{keyword}ã€‘è¿›è¡Œå…¨ç½‘æœç´¢"
                            
                            # æ ¼å¼åŒ–ç»“æœ
                            result_text = f"ğŸ” æœ¬åœ°æ•°æ®åº“æ‰¾åˆ° {len(results)} ä¸ªç›¸å…³èµ„æºï¼š\n\n"
                            
                            for i, item in enumerate(results, 1):
                                title = item.get('title', 'æœªçŸ¥æ ‡é¢˜')
                                url_link = item.get('url', '')
                                is_time = item.get('is_time', 0)
                                
                                # è¯†åˆ«ç½‘ç›˜ç±»å‹
                                pan_type_name = "æœªçŸ¥"
                                if 'quark.cn' in url_link:
                                    pan_type_name = "å¤¸å…‹"
                                elif 'pan.baidu.com' in url_link:
                                    pan_type_name = "ç™¾åº¦"
                                elif 'drive.uc.cn' in url_link:
                                    pan_type_name = "UC"
                                elif 'pan.xunlei.com' in url_link:
                                    pan_type_name = "è¿…é›·"
                                elif 'aliyundrive.com' in url_link or 'alipan.com' in url_link:
                                    pan_type_name = "é˜¿é‡Œ"
                                
                                # æ ¹æ®æ˜¯å¦æ˜¯ä¸´æ—¶èµ„æºæ·»åŠ ä¸åŒçš„å›¾æ ‡
                                if is_time == 1:
                                    result_text += f"{i}. ã€{pan_type_name}ã€‘{title}\nğŸŒ é“¾æ¥: {url_link}\n\n"
                                else:
                                    result_text += f"{i}. ã€{pan_type_name}ã€‘{title}\nğŸ”— é“¾æ¥: {url_link}\n\n"
                            
                            result_text += "â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n"
                            
                            # æ£€æŸ¥æ˜¯å¦æœ‰ä¸´æ—¶èµ„æº
                            has_temp = any(item.get('is_time') == 1 for item in results)
                            if has_temp:
                                result_text += "ğŸŒ èµ„æºæ¥æºç½‘ç»œï¼Œ30åˆ†é’Ÿååˆ é™¤\n"
                                result_text += "â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n"
                            
                            result_text += f"ğŸ’¡ æç¤ºï¼šç»“æœä¸æ»¡æ„ï¼Œè¯·è¾“å…¥ã€æœ{keyword}ã€‘ï¼Œè¿›è¡Œå…¨ç½‘æœç´¢"
                            
                            return result_text
                        else:
                            return f"âŒ æœ¬åœ°æ•°æ®åº“æœªæ‰¾åˆ°ç›¸å…³èµ„æº\n\nğŸ’¡ æç¤ºï¼šå¯ä»¥å°è¯•ä½¿ç”¨ã€æœ{keyword}ã€‘è¿›è¡Œå…¨ç½‘æœç´¢"
                    elif response.status == 404:
                        return f"âŒ æœ¬åœ°æ•°æ®åº“æœªæ‰¾åˆ°ç›¸å…³èµ„æº\n\nğŸ’¡ æç¤ºï¼šå¯ä»¥å°è¯•ä½¿ç”¨ã€{keyword}ã€‘è¿›è¡Œå…¨ç½‘æœç´¢"
                    else:
                        return "âŒ æœç´¢æœåŠ¡å¼‚å¸¸ï¼Œè¯·ç¨åé‡è¯•"
                        
        except asyncio.TimeoutError:
            # è¶…æ—¶å¯èƒ½æ˜¯å› ä¸ºæ•°æ®åº“æ²¡ç»“æœï¼Œæ¥å£åœ¨æ‰§è¡Œå…¨ç½‘æœç´¢
            # æˆ‘ä»¬ç›´æ¥è¿”å›æœªæ‰¾åˆ°
            logger.warning(f"æœ¬åœ°æœç´¢è¶…æ—¶ï¼ˆå¯èƒ½æ•°æ®åº“æ— ç»“æœï¼‰: {keyword}")
            return f"âŒ æœ¬åœ°æ•°æ®åº“æœªæ‰¾åˆ°ç›¸å…³èµ„æº: {keyword}\n\nğŸ’¡ æç¤ºï¼šå¯ä»¥å°è¯•ä½¿ç”¨ã€æœ{keyword}ã€‘è¿›è¡Œå…¨ç½‘æœç´¢"
        except Exception as e:
            logger.error(f"æœ¬åœ°æœç´¢å¤±è´¥: {str(e)}")
            return "âŒ æœç´¢å¤±è´¥ï¼Œè¯·ç¨åé‡è¯•"

    async def _full_network_search(self, keyword: str) -> str:
        """å…¨ç½‘æœç´¢ï¼Œä¾æ¬¡æœç´¢å¤šç§ç½‘ç›˜ç±»å‹"""
        # è¾“å…¥éªŒè¯
        if not keyword or not keyword.strip():
            return self.messages['empty_keyword']

        results = []
        success_count = 0

        # ä¾æ¬¡æœç´¢å¤¸å…‹ã€ç™¾åº¦ã€UCã€è¿…é›·
        for pan_name, pan_type in self.search_types.items():
            try:
                # ä½¿ç”¨ç»Ÿä¸€çš„ä¼šè¯key
                dummy_key = "dummy"  # å…¨ç½‘æœç´¢ä¸éœ€è¦ä¿å­˜ä¼šè¯
                result = await self._search_resources(dummy_key, keyword, is_full_network=False, pan_type=pan_type)
                if self.messages['no_resources_found'].format('') not in result and self.messages['search_failed'] not in result and self.messages['search_service_unavailable_temporarily'] not in result:
                    results.append(f"ã€{pan_name}ç½‘ç›˜ã€‘\n{result}")
                    success_count += 1
                elif self.messages['search_service_unavailable_temporarily'] in result:
                    # å¦‚æœæœåŠ¡ä¸å¯ç”¨ï¼Œè¿”å›é”™è¯¯ä¿¡æ¯
                    return result

                # æ·»åŠ å»¶æ—¶é¿å…è¯·æ±‚è¿‡äºé¢‘ç¹
                await asyncio.sleep(0.5)
            except Exception as e:
                logger.error(f"æœç´¢{pan_name}ç½‘ç›˜æ—¶å‘ç”Ÿé”™è¯¯: {str(e)}")
                continue

        if success_count == 0:
            return self.messages['no_resources_found'].format(keyword)

        # åˆå¹¶ç»“æœ
        return self.messages['full_network_search_results'].format(keyword) + "\n\n".join(results)

    async def _format_search_results(self, user_session_key: str, data, keyword: str, is_full_network: bool, page: int = 1) -> str:
        """æ ¼å¼åŒ–æœç´¢ç»“æœï¼Œæ”¯æŒåˆ†é¡µåŠŸèƒ½"""
        try:
            # åˆå§‹åŒ–ç»“æœåˆ—è¡¨
            result_list = []

            # å¤„ç†ä¸åŒæ ¼å¼çš„å“åº”æ•°æ®
            if isinstance(data, list):
                result_list = data
            elif isinstance(data, dict):
                # å¦‚æœæ˜¯åŒ…å«'result'å­—æ®µçš„å­—å…¸
                if 'result' in data:
                    result_list = data['result']
                # å¦‚æœæ˜¯åŒ…å«'data'å­—æ®µçš„å­—å…¸
                elif 'data' in data:
                    result_list = data['data']
                # å¦‚æœæ˜¯åŒ…å«'list'å­—æ®µçš„å­—å…¸
                elif 'list' in data:
                    result_list = data['list']
                # å¦‚æœå“åº”æ˜¯{'code': 0, 'msg': 'success', 'data': [...]}æ ¼å¼
                elif 'code' in data and data.get('code') == 0 and 'data' in data:
                    result_list = data['data']
            elif isinstance(data, str):
                # å¦‚æœæ˜¯å­—ç¬¦ä¸²ï¼Œå¯èƒ½æ˜¯SSEå“åº”æ–‡æœ¬ï¼Œéœ€è¦é‡æ–°è§£æ
                if user_session_key in self.user_sessions:
                    session_data = self.user_sessions[user_session_key]
                    if session_data.get('is_sse', False):
                        # å¯¹äºSSEå“åº”ï¼Œç›´æ¥è§£ææ•°æ®è€Œä¸æ˜¯å†æ¬¡è°ƒç”¨_parse_sse_response
                        # å› ä¸º_parse_sse_responseä¼šå†æ¬¡è°ƒç”¨æ­¤æ–¹æ³•å¯¼è‡´å¾ªç¯

                        # åˆ†å‰²SSEæ¶ˆæ¯
                        lines = data.strip().split('\n')
                        data_lines = [
                            line for line in lines if line.startswith('data:')]

                        # æå–JSONæ•°æ®
                        json_data_list = []
                        for data_line in data_lines:
                            # ç§»é™¤"data:"å‰ç¼€å¹¶è§£æJSON
                            json_str = data_line[5:].strip()
                            if json_str and json_str != '[DONE]':
                                import json
                                try:
                                    json_data = json.loads(json_str)
                                    json_data_list.append(json_data)
                                except json.JSONDecodeError:
                                    continue

                        # åˆå¹¶æ‰€æœ‰æ•°æ®
                        combined_data = []
                        for json_data in json_data_list:
                            # ç›´æ¥å¤„ç†JSONå¯¹è±¡ï¼Œè€Œä¸æ˜¯æœŸæœ›å®ƒæœ‰'data'å­—æ®µ
                            if isinstance(json_data, dict):
                                # å¦‚æœæ˜¯å­—å…¸ä¸”æœ‰'url'å­—æ®µï¼Œè¯´æ˜æ˜¯æˆ‘ä»¬éœ€è¦çš„æ•°æ®é¡¹
                                if 'url' in json_data:
                                    combined_data.append(json_data)
                                # å¦‚æœæœ‰'data'å­—æ®µä¸”æ˜¯åˆ—è¡¨ï¼Œæ‰©å±•å®ƒ
                                elif 'data' in json_data and isinstance(json_data['data'], list):
                                    combined_data.extend(json_data['data'])
                                # å¦‚æœæ˜¯å…¶ä»–å­—å…¸å½¢å¼ï¼Œç›´æ¥æ·»åŠ 
                                else:
                                    combined_data.append(json_data)
                            elif isinstance(json_data, list):
                                combined_data.extend(json_data)

                        result_list = combined_data
            else:
                # å¦‚æœdataä¸æ˜¯åˆ—è¡¨ä¹Ÿä¸æ˜¯å­—å…¸ï¼Œåˆ™ç›´æ¥è¿”å›ç©ºç»“æœ
                return self.messages['no_resources_found'].format(keyword)

            # å¦‚æœæ²¡æœ‰ç»“æœï¼Œç›´æ¥è¿”å›
            if not result_list:
                return self.messages['no_resources_found'].format(keyword)

            # åˆ†é¡µå¤„ç†ï¼Œä½¿ç”¨é…ç½®ä¸­çš„æ¯é¡µç»“æœæ•°
            page_size = self.results_per_page
            total_results = len(result_list)
            total_pages = (total_results + page_size - 1) // page_size  # è®¡ç®—æ€»é¡µæ•°

            # æ›´æ–°ç”¨æˆ·ä¼šè¯ä¸­çš„æ€»é¡µæ•°
            if user_session_key in self.user_sessions:
                self.user_sessions[user_session_key]['total_pages'] = total_pages

            # éªŒè¯é¡µç æœ‰æ•ˆæ€§
            if page < 1 or page > total_pages:
                return self.messages['invalid_page_number'].format(total_pages)

            # è®¡ç®—å½“å‰é¡µçš„èµ·å§‹å’Œç»“æŸç´¢å¼•
            start_index = (page - 1) * page_size
            end_index = min(start_index + page_size, total_results)

            # è·å–å½“å‰é¡µçš„ç»“æœ
            current_page_results = result_list[start_index:end_index]

            # å¹¶å‘è½¬å­˜å¹¶æ ¼å¼åŒ–ç»“æœï¼ˆæ€§èƒ½ä¼˜åŒ–ï¼‰
            formatted_results = await self._transfer_and_format_results(current_page_results, start_index)

            # æ„é€ ç»“æœæ–‡æœ¬ï¼Œä½¿ç”¨æ–°çš„æ ¼å¼
            result_text = self.messages['search_results_header'].format(
                total_results) + '\n\n' + '\n\n'.join(formatted_results)

            # æ·»åŠ åˆ†éš”çº¿å’Œé¡µç ä¿¡æ¯
            result_text += '\n\n' + self.messages['search_results_separator'] + '\n' + self.messages['search_results_footer'] + '\n' + self.messages['search_results_separator_footer']
            
            # æ·»åŠ ç½‘ç«™æ¨å¹¿é“¾æ¥
            result_text += '\n' + self.messages['search_results_website_promo'].format(self.base_url) + '\n' + self.messages['search_results_separator_footer']
            
            # åªæœ‰å¯ç”¨åˆ†é¡µåŠŸèƒ½æ—¶æ‰æ˜¾ç¤ºåˆ†é¡µä¿¡æ¯
            if self.enable_pagination:
                result_text += '\n' + self.messages['search_results_page_info'].format(
                    page, total_pages) + '\n' + self.messages['search_results_navigation']

            return result_text
        except Exception as e:
            logger.error(f"æ ¼å¼åŒ–æœç´¢ç»“æœæ—¶å‘ç”Ÿé”™è¯¯: {str(e)}")
            return self.messages['format_search_error']

    async def _transfer_and_format_results(self, results: list, start_index: int) -> list:
        """å¹¶å‘è½¬å­˜å¹¶æ ¼å¼åŒ–ç»“æœï¼ˆæ€§èƒ½ä¼˜åŒ–ï¼‰"""
        if not self.enable_transfer or not self.api_key:
            # è½¬å­˜æœªå¯ç”¨ï¼Œç›´æ¥è¿”å›åŸå§‹é“¾æ¥
            return self._format_results_without_transfer(results, start_index)

        # é¢„å…ˆè·å–æ‰€æœ‰éœ€è¦çš„Cookieï¼ˆé¿å…åœ¨å¹¶å‘ä»»åŠ¡ä¸­é‡å¤è¯·æ±‚ï¼‰
        pan_types_needed = set()
        for item in results:
            url = item.get('url', '')
            if url:
                pan_type = self._identify_pan_type(url)
                if pan_type in ['quark', 'baidu', 'uc', 'xunlei', 'ali']:
                    pan_types_needed.add(pan_type)
        
        # å¹¶å‘è·å–æ‰€æœ‰éœ€è¦çš„Cookie
        await self._prefetch_cookies(pan_types_needed)

        # åˆ›å»ºè½¬å­˜ä»»åŠ¡
        tasks = []
        for i, item in enumerate(results):
            global_index = start_index + i + 1
            title = item.get('title', self.messages['resource_title_default'])
            url = item.get('url', '')
            
            if url:
                pan_type = self._identify_pan_type(url)
                if pan_type in ['quark', 'baidu', 'uc', 'xunlei', 'ali']:
                    # åˆ›å»ºè½¬å­˜ä»»åŠ¡
                    task = self._transfer_single_resource(global_index, title, url)
                    tasks.append(task)
                else:
                    # ä¸æ”¯æŒçš„ç½‘ç›˜ç±»å‹ï¼Œç›´æ¥æ ¼å¼åŒ–
                    tasks.append(self._format_single_result(global_index, title, url, None))
            else:
                tasks.append(self._format_single_result(global_index, title, '', None))

        # å¹¶å‘æ‰§è¡Œæ‰€æœ‰è½¬å­˜ä»»åŠ¡
        results = await asyncio.gather(*tasks, return_exceptions=True)
        
        # å¤„ç†ç»“æœ
        formatted = []
        for result in results:
            if isinstance(result, Exception):
                logger.error(f"è½¬å­˜ä»»åŠ¡å¼‚å¸¸: {str(result)}")
                formatted.append("âš ï¸ å¤„ç†å¤±è´¥")
            else:
                formatted.append(result)
        
        return formatted

    async def _transfer_single_resource(self, index: int, title: str, url: str) -> str:
        """è½¬å­˜å•ä¸ªèµ„æºå¹¶è¿”å›æ ¼å¼åŒ–ç»“æœ"""
        try:
            # æå–å¯†ç 
            parsed_url = urlparse(url)
            query_params = parse_qs(parsed_url.query)
            pwd_code = query_params.get('pwd', [''])[0]
            
            transfer_result = await self._transfer_and_share(url, pwd_code)
            
            if transfer_result['success']:
                new_title = transfer_result['title']
                new_url = transfer_result['share_url']
                return f"{index}. {new_title}\nâœ… é“¾æ¥: {new_url}"
            else:
                # è½¬å­˜å¤±è´¥ï¼Œä¸è¿”å›åŸå§‹é“¾æ¥
                return f"{index}. {title}\nâŒ è½¬å­˜å¤±è´¥ï¼Œè¯·å°è¯•æœç´¢å…¶ä»–ç½‘ç›˜"
        except Exception as e:
            logger.error(f"è½¬å­˜èµ„æºå¤±è´¥: {str(e)}")
            # è½¬å­˜å¼‚å¸¸ï¼Œä¸è¿”å›åŸå§‹é“¾æ¥
            return f"{index}. {title}\nâŒ è½¬å­˜å¤±è´¥ï¼Œè¯·å°è¯•æœç´¢å…¶ä»–ç½‘ç›˜"

    async def _format_single_result(self, index: int, title: str, url: str, transfer_result) -> str:
        """æ ¼å¼åŒ–å•ä¸ªç»“æœ"""
        if url:
            return f"{index}. {title}\né“¾æ¥: {url}"
        return f"{index}. {title}"

    def _format_results_without_transfer(self, results: list, start_index: int) -> list:
        """ä¸è½¬å­˜ç›´æ¥æ ¼å¼åŒ–ç»“æœ"""
        formatted = []
        for i, item in enumerate(results):
            global_index = start_index + i + 1
            title = item.get('title', self.messages['resource_title_default'])
            url = item.get('url', '')
            
            if url:
                formatted.append(f"{global_index}. {title}\nğŸ”— é“¾æ¥: {url}")
            else:
                formatted.append(f"{global_index}. {title}")
        return formatted

    def _identify_pan_type(self, url: str) -> str:
        """æ ¹æ®URLè¯†åˆ«ç½‘ç›˜ç±»å‹"""
        domain_patterns = {
            'quark': ['pan.quark.cn'],
            'ali': ['www.alipan.com', 'www.aliyundrive.com'],
            'baidu': ['pan.baidu.com'],
            'uc': ['drive.uc.cn', 'fast.uc.cn'],
            'xunlei': ['pan.xunlei.com']
        }

        # è½¬æ¢URLä¸ºå°å†™ä»¥å¤„ç†å¤§å°å†™ä¸ä¸€è‡´çš„æƒ…å†µ
        lower_url = url.lower()

        for pan_type, patterns in domain_patterns.items():
            for pattern in patterns:
                if pattern in lower_url:
                    return pan_type

        return 'quark'  # é»˜è®¤è¿”å›å¤¸å…‹

    async def _prefetch_cookies(self, pan_types: set):
        """é¢„å…ˆå¹¶å‘è·å–æ‰€æœ‰éœ€è¦çš„Cookieï¼ˆæ€§èƒ½ä¼˜åŒ–ï¼‰"""
        tasks = []
        for pan_type in pan_types:
            # æ£€æŸ¥ç¼“å­˜ä¸­æ˜¯å¦æœ‰Cookieæˆ–å·²è¿‡æœŸï¼ˆ5åˆ†é’Ÿï¼‰
            cache_entry = self._cookie_cache.get(pan_type)
            if not cache_entry or (time.time() - cache_entry[1] > 300):  # 5åˆ†é’Ÿè¿‡æœŸ
                tasks.append(self._get_actual_cookie_value(pan_type))
        
        # å¹¶å‘è·å–æ‰€æœ‰Cookie
        if tasks:
            await asyncio.gather(*tasks, return_exceptions=True)

    async def _get_actual_cookie_value(self, pan_type: str) -> str:
        """ä»å¿ƒæ‚¦APIè·å–æŒ‡å®šç½‘ç›˜çš„å®é™…Cookieå€¼ï¼ˆå¸¦ç¼“å­˜ï¼‰"""
        # æ£€æŸ¥ç¼“å­˜
        cache_entry = self._cookie_cache.get(pan_type)
        if cache_entry and (time.time() - cache_entry[1] < 300):  # 5åˆ†é’Ÿå†…æœ‰æ•ˆ
            return cache_entry[0]
        
        # æ ¹æ®ç½‘ç›˜ç±»å‹ç¡®å®šAPIç«¯ç‚¹
        api_endpoints = {
            'quark': 'quark',
            'baidu': 'baidu',
            'uc': 'uc',
            'xunlei': 'xunlei',
            'ali': 'ali'
        }

        if pan_type not in api_endpoints:
            logger.warning(f"ä¸æ”¯æŒçš„ç½‘ç›˜ç±»å‹: {pan_type}")
            return ""

        try:
            async with aiohttp.ClientSession() as session:
                # ä½¿ç”¨æ­£ç¡®çš„APIè·¯å¾„
                api_url = f"{self.base_url}/api/GetCookie/{api_endpoints[pan_type]}"

                async with session.get(
                    api_url,
                    timeout=aiohttp.ClientTimeout(total=10)
                ) as response:
                    if response.status == 200:
                        result = await response.json()
                        if result.get('code') == 200:
                            # ä»è¿”å›çš„æ•°æ®ä¸­æå–å®é™…çš„Cookieå€¼
                            cookie_key = f"{pan_type}_cookie"
                            actual_cookie = result.get('data', {}).get(cookie_key, "")
                            if actual_cookie:
                                # ç¼“å­˜Cookie
                                self._cookie_cache[pan_type] = (actual_cookie, time.time())
                                logger.info(f"âœ… è·å–{pan_type}ç½‘ç›˜CookieæˆåŠŸ")
                                return actual_cookie
                            else:
                                return ""
                        else:
                            return ""
                    else:
                        return ""
        except Exception as e:
            logger.error(f"âŒ è·å–{pan_type}ç½‘ç›˜Cookieå¼‚å¸¸: {str(e)}")
            return ""

    async def _get_cookie_from_database(self, pan_type: str) -> str:
        """ä»å¿ƒæ‚¦æ•°æ®åº“è·å–æŒ‡å®šç½‘ç›˜çš„Cookie"""
        # æ ¹æ®ç½‘ç›˜ç±»å‹ç¡®å®šAPIç«¯ç‚¹
        api_endpoints = {
            'quark': 'quark',
            'baidu': 'baidu',
            'uc': 'uc',
            'xunlei': 'xunlei',
            'ali': 'ali'
        }

        if pan_type not in api_endpoints:
            logger.warning(f"ä¸æ”¯æŒçš„ç½‘ç›˜ç±»å‹: {pan_type}")
            return ""

        try:
            async with aiohttp.ClientSession() as session:
                # ä½¿ç”¨æ­£ç¡®çš„APIè·¯å¾„
                api_url = f"{self.base_url}/api/GetCookie/{api_endpoints[pan_type]}"

                async with session.get(
                    api_url,
                    timeout=aiohttp.ClientTimeout(total=10)
                ) as response:
                    if response.status == 200:
                        return "API_SUCCESS"
                    else:
                        return ""
        except Exception as e:
            logger.error(f"âŒ è·å–{pan_type}ç½‘ç›˜Cookieå¼‚å¸¸: {str(e)}")
            return ""

    def _parse_sse_response(self, text: str, keyword: str, page: int = 1) -> str:
        """è§£æSSEæµå¼å“åº”"""
        try:
            # åˆ†å‰²SSEæ¶ˆæ¯
            lines = text.strip().split('\n')
            data_lines = [line for line in lines if line.startswith('data:')]

            # æå–JSONæ•°æ®
            json_data_list = []
            for data_line in data_lines:
                # ç§»é™¤"data:"å‰ç¼€å¹¶è§£æJSON
                json_str = data_line[5:].strip()
                if json_str and json_str != '[DONE]':
                    import json
                    try:
                        json_data = json.loads(json_str)
                        json_data_list.append(json_data)
                    except json.JSONDecodeError:
                        continue

            # å¦‚æœæ²¡æœ‰æœ‰æ•ˆæ•°æ®ï¼Œè¿”å›ç©ºåˆ—è¡¨
            if not json_data_list:
                return []

            # åˆå¹¶æ‰€æœ‰æ•°æ®
            combined_data = []
            for json_data in json_data_list:
                # ç›´æ¥å¤„ç†JSONå¯¹è±¡ï¼Œè€Œä¸æ˜¯æœŸæœ›å®ƒæœ‰'data'å­—æ®µ
                if isinstance(json_data, dict):
                    # å¦‚æœæ˜¯å­—å…¸ä¸”æœ‰'url'å­—æ®µï¼Œè¯´æ˜æ˜¯æˆ‘ä»¬éœ€è¦çš„æ•°æ®é¡¹
                    if 'url' in json_data:
                        combined_data.append(json_data)
                    # å¦‚æœæœ‰'data'å­—æ®µä¸”æ˜¯åˆ—è¡¨ï¼Œæ‰©å±•å®ƒ
                    elif 'data' in json_data and isinstance(json_data['data'], list):
                        combined_data.extend(json_data['data'])
                    # å¦‚æœæ˜¯å…¶ä»–å­—å…¸å½¢å¼ï¼Œç›´æ¥æ·»åŠ 
                    else:
                        combined_data.append(json_data)
                elif isinstance(json_data, list):
                    combined_data.extend(json_data)

            # ç›´æ¥è¿”å›è§£æåçš„æ•°æ®åˆ—è¡¨ï¼Œè®©è°ƒç”¨è€…å¤„ç†æ ¼å¼åŒ–
            return combined_data
        except Exception as e:
            logger.error(f"è§£æSSEå“åº”æ—¶å‘ç”Ÿé”™è¯¯: {str(e)}")
            return []

    async def _transfer_and_share(self, url: str, code: str = "") -> dict:
        """è°ƒç”¨å¿ƒæ‚¦è½¬å­˜å†åˆ†äº«APIï¼Œè¿”å›åŒ…å«æ ‡é¢˜å’Œé“¾æ¥çš„å­—å…¸"""
        try:
            # ä½¿ç”¨é…ç½®æ–‡ä»¶ä¸­çš„APIå¯†é’¥
            api_key = self.api_key
            if not api_key:
                return {'success': False, 'error': self.messages['api_key_not_configured']}

            # æ ¹æ®URLè¯†åˆ«ç½‘ç›˜ç±»å‹
            pan_type = self._identify_pan_type(url)
            
            # ä»å¿ƒæ‚¦æ•°æ®åº“è·å–Cookie
            actual_cookie = ""
            cache_entry = self._cookie_cache.get(pan_type)
            if cache_entry and (time.time() - cache_entry[1] < 300):  # 5åˆ†é’Ÿå†…æœ‰æ•ˆ
                actual_cookie = cache_entry[0]
            else:
                # ç¼“å­˜å¤±æ•ˆï¼Œä»APIè·å–
                cookie_status = await self._get_cookie_from_database(pan_type)
                if not cookie_status:
                    logger.warning(f"âŒ è·å–{pan_type}ç½‘ç›˜Cookieå¤±è´¥")
                    return {'success': False, 'error': 'æŠ±æ­‰ï¼Œcookieè¿‡æœŸï¼Œè¯·è”ç³»ç¾¤ä¸»ï¼'}
                else:
                    # è·å–å®é™…çš„Cookieå€¼ï¼ˆä¼šè‡ªåŠ¨ç¼“å­˜ï¼‰
                    actual_cookie = await self._get_actual_cookie_value(pan_type)
                    if not actual_cookie:
                        logger.warning(f"âŒ è·å–{pan_type}ç½‘ç›˜Cookieå¤±è´¥")
                        return {'success': False, 'error': 'æŠ±æ­‰ï¼Œcookieè¿‡æœŸï¼Œè¯·è”ç³»ç¾¤ä¸»ï¼'}

            # æ„å»ºè½¬å­˜APIè¯·æ±‚æ•°æ®
            transfer_data = {
                'url': url,
                'code': code,
                'expired_type': 2,  # 1ä¸ºæ°¸ä¹…èµ„æºï¼Œ2ä¸ºä¸´æ—¶èµ„æº
                'isType': 0,  # 0è½¬å­˜å¹¶åˆ†äº«ï¼Œ1ç›´æ¥è·å–èµ„æºä¿¡æ¯
                'api_key': api_key,  # ä½¿ç”¨ä»é…ç½®è·å–çš„APIå¯†é’¥
                'isSave': 1  # æ·»åŠ æ­¤å‚æ•°ä»¥ä¿å­˜åˆ°æ•°æ®åº“
            }

            # æ³¨æ„ï¼šå¯¹äºè¿…é›·ç½‘ç›˜ï¼ŒCookieåº”è¯¥é€šè¿‡å¿ƒæ‚¦ç³»ç»Ÿçš„é…ç½®æœºåˆ¶ä¼ é€’ï¼Œ
            # è€Œä¸æ˜¯é€šè¿‡HTTPè¯·æ±‚å¤´ã€‚å¿ƒæ‚¦ç³»ç»Ÿä¼šä»æ•°æ®åº“é…ç½®ä¸­è¯»å–Cookieã€‚
            headers = {
                'Content-Type': 'application/json'
            }

            # è°ƒç”¨å¿ƒæ‚¦è½¬å­˜API
            async with aiohttp.ClientSession() as session:
                async with session.post(
                    f"{self.base_url}/api/open/transfer",
                    json=transfer_data,
                    headers=headers,
                    timeout=aiohttp.ClientTimeout(total=30)
                ) as response:
                    if response.status == 200:
                        result = await response.json()
                        if result.get('code') == 200:
                            # è½¬å­˜æˆåŠŸï¼Œè¿”å›åˆ†äº«ä¿¡æ¯
                            # å¿ƒæ‚¦ç³»ç»Ÿä¼šè‡ªåŠ¨å°†ç»“æœä¿å­˜åˆ°æ•°æ®åº“ï¼ˆå› ä¸ºisSave=1ï¼‰
                            return {
                                'success': True,
                                'title': result['data']['title'],
                                'share_url': result['data']['share_url']
                            }
                        else:
                            return {
                                'success': False,
                                'error': result.get('message', self.messages['unknown_error'])
                            }
                    else:
                        return {
                            'success': False,
                            'error': self.messages['transfer_service_error'].format(response.status)
                        }

        except asyncio.TimeoutError:
            return {'success': False, 'error': self.messages['transfer_timeout']}
        except Exception as e:
            logger.error(f"è½¬å­˜è¿‡ç¨‹ä¸­å‘ç”Ÿé”™è¯¯ï¼š{str(e)}")
            return {'success': False, 'error': self.messages['transfer_process_error'].format(str(e))}

    @filter.command("ä½¿ç”¨æ–¹æ³•")
    async def show_usage(self, event: AstrMessageEvent):
        """æ˜¾ç¤ºæœºå™¨äººä½¿ç”¨æ–¹æ³•"""
        try:
            usage_info = f"""ğŸ“– å¿ƒæ‚¦æœç´¢æœºå™¨äººä½¿ç”¨æŒ‡å—

ğŸ” åŸºç¡€æœç´¢æŒ‡ä»¤ï¼š
â€¢ æ‰¾ + å…³é”®è¯ â†’ æœ¬åœ°æœç´¢ï¼ˆåªæŸ¥æœ¬åœ°æ•°æ®åº“ï¼Œé€Ÿåº¦å¿«ï¼‰
  ç¤ºä¾‹ï¼šæ‰¾å¤ä»‡è€…è”ç›Ÿ

â€¢ æœ + å…³é”®è¯ â†’ å…¨ç½‘æœç´¢ï¼ˆä»å¤–éƒ¨APIæœç´¢ï¼‰
  ç¤ºä¾‹ï¼šæœå¤ä»‡è€…è”ç›Ÿ

â€¢ ç™¾åº¦ + å…³é”®è¯ â†’ æœç´¢ç™¾åº¦ç½‘ç›˜èµ„æº
  ç¤ºä¾‹ï¼šç™¾åº¦å¤ä»‡è€…è”ç›Ÿ

â€¢ uc/UC + å…³é”®è¯ â†’ æœç´¢UCç½‘ç›˜èµ„æº
  ç¤ºä¾‹ï¼šucå¤ä»‡è€…è”ç›Ÿ

â€¢ è¿…é›· + å…³é”®è¯ â†’ æœç´¢è¿…é›·ç½‘ç›˜èµ„æº
  ç¤ºä¾‹ï¼šè¿…é›·å¤ä»‡è€…è”ç›Ÿ

ğŸ“„ ç¿»é¡µæŒ‡ä»¤ï¼š
â€¢ ä¸Š æˆ– 0 â†’ æŸ¥çœ‹ä¸Šä¸€é¡µ
â€¢ ä¸‹ æˆ– 1 â†’ æŸ¥çœ‹ä¸‹ä¸€é¡µ

ğŸ’¡ æœç´¢æŠ€å·§ï¼š
â€¢ ä¼˜å…ˆä½¿ç”¨"æ‰¾"è¿›è¡Œå¿«é€ŸæŸ¥è¯¢
â€¢ æœ¬åœ°æ— ç»“æœæ—¶å†ä½¿ç”¨"æœ"è¿›è¡Œå…¨ç½‘æœç´¢
â€¢ å…³é”®è¯å°½é‡ç®€çŸ­å‡†ç¡®

ğŸ”— é“¾æ¥çŠ¶æ€è¯´æ˜ï¼š
â€¢ âœ… = è½¬å­˜æˆåŠŸï¼ˆå·²è½¬å­˜å¹¶ç”Ÿæˆæ–°é“¾æ¥ï¼‰
â€¢ âŒ = è½¬å­˜å¤±è´¥ï¼ˆè½¬å­˜å¤±è´¥ï¼Œè¯·å°è¯•æœç´¢å…¶ä»–ç½‘ç›˜ï¼‰
â€¢ ğŸ”— = ç›´æ¥åˆ†äº«ï¼ˆæœªå¯ç”¨è½¬å­˜ï¼‰
â€¢ ğŸŒ = ä¸´æ—¶èµ„æºï¼ˆ30åˆ†é’Ÿååˆ é™¤ï¼‰

â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
æ›´å¤šèµ„æºè¯·è®¿é—®ï¼š{self.base_url}"""

            yield event.plain_result(usage_info)

        except Exception as e:
            logger.error(f"æ˜¾ç¤ºä½¿ç”¨æ–¹æ³•æ—¶å‘ç”Ÿé”™è¯¯: {str(e)}")
            yield event.plain_result("âŒ è·å–ä½¿ç”¨æ–¹æ³•å¤±è´¥ï¼Œè¯·ç¨åé‡è¯•")

    async def terminate(self):
        """æ’ä»¶é”€æ¯æ–¹æ³•"""
        logger.info("å¿ƒæ‚¦æœç´¢æœºå™¨äººæ’ä»¶å·²ç»ˆæ­¢")