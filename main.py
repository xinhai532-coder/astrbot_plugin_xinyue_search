import asyncio
import aiohttp
import yaml
import os
import time
from urllib.parse import urlparse, parse_qs
from astrbot.api.event import filter, AstrMessageEvent, MessageEventResult
from astrbot.api.star import Context, Star, register
from astrbot.api import logger
from typing import Dict, List
from collections import defaultdict
class RateLimiter:
    def __init__(self, max_requests: int = 10, window_seconds: int = 60):
        self.max_requests = max_requests
        self.window_seconds = window_seconds
        self.requests: Dict[str, List[float]] = defaultdict(list)
    def is_allowed(self, user_id: str) -> bool:
        now = time.time()
        self.requests[user_id] = [
            t for t in self.requests[user_id] 
            if now - t < self.window_seconds
        ]
        if len(self.requests[user_id]) >= self.max_requests:
            return False
        self.requests[user_id].append(now)
        return True
    def get_wait_time(self, user_id: str) -> int:
        if not self.requests[user_id]:
            return 0
        oldest = min(self.requests[user_id])
        wait = self.window_seconds - (time.time() - oldest)
        return max(0, int(wait))
@register("astrbot_plugin_xinyue_search", "é˜¿ç«‹", "å¿ƒæ‚¦æœç´¢æœºå™¨äººæ’ä»¶", "1.4.0")
class XinyueSearchBotPlugin(Star):
    def __init__(self, context: Context, config: dict = None):
        super().__init__(context)
        license_token = config.get('license_token', '') if config else ''
        config_qq = config.get('bot_qq', '') if config else ''
        actual_qq = ''
        try:
            if hasattr(context, 'base_config') and context.base_config:
                if hasattr(context.base_config, 'platform_settings'):
                    for platform in context.base_config.platform_settings:
                        if hasattr(platform, 'account') and platform.account:
                            actual_qq = str(platform.account)
                            logger.info(f"âœ“ æ£€æµ‹åˆ°å®é™…è¿è¡Œçš„æœºå™¨äººQQå·: {actual_qq}")
                            break
            if not actual_qq and hasattr(context, 'config_helper'):
                config_helper = context.config_helper
                if hasattr(config_helper, 'get_platform_config'):
                    platform_config = config_helper.get_platform_config()
                    if platform_config and 'account' in platform_config:
                        actual_qq = str(platform_config['account'])
                        logger.info(f"âœ“ æ£€æµ‹åˆ°å®é™…è¿è¡Œçš„æœºå™¨äººQQå·: {actual_qq}")
        except Exception as e:
            logger.warning(f"è‡ªåŠ¨è·å–æœºå™¨äººQQå·å¤±è´¥: {e}")
        bot_qq = ''
        if license_token:
            if not config_qq:
                raise Exception(
                    "âŒ ä½¿ç”¨æ­£å¼æˆæƒæ—¶å¿…é¡»é…ç½® bot_qq\n"
                    "ğŸ’¡ è¯·åœ¨é…ç½®ä¸­å¡«å†™ä½ çš„æœºå™¨äººQQå·\n"
                    "ğŸ’¡ å¦‚æœåªæ˜¯è¯•ç”¨ï¼Œè¯·ä¸è¦å¡«å†™ license_token"
                )
            if actual_qq and config_qq != actual_qq:
                raise Exception(
                    f"âŒ é…ç½®çš„QQå·ä¸å®é™…è¿è¡Œçš„QQå·ä¸ä¸€è‡´\n"
                    f"ğŸ’¡ é…ç½®çš„QQå·: {config_qq}\n"
                    f"ğŸ’¡ å®é™…è¿è¡Œçš„QQå·: {actual_qq}\n"
                    f"ğŸ’¡ è¯·ä¿®æ”¹é…ç½®ä¸­çš„ bot_qq ä¸ºå®é™…è¿è¡Œçš„QQå·"
                )
            bot_qq = config_qq
            logger.info(f"âœ“ ä½¿ç”¨é…ç½®çš„QQå·: {bot_qq}")
        else:
            if actual_qq:
                bot_qq = actual_qq
                if config_qq and config_qq != actual_qq:
                    logger.warning(f"âš  é…ç½®çš„QQå·({config_qq})ä¸å®é™…QQå·({actual_qq})ä¸ä¸€è‡´ï¼Œä½¿ç”¨å®é™…QQå·")
            elif config_qq:
                bot_qq = config_qq
                logger.info(f"âœ“ ä½¿ç”¨é…ç½®çš„QQå·: {bot_qq}")
            else:
                import hashlib
                plugin_dir = os.path.dirname(__file__)
                bot_qq = hashlib.md5(plugin_dir.encode()).hexdigest()[:10]
                logger.warning(f"âš  æ— æ³•è·å–æœºå™¨äººQQå·ï¼Œä½¿ç”¨ä¸´æ—¶æ ‡è¯†: {bot_qq}")
                logger.warning("ğŸ’¡ å»ºè®®åœ¨é…ç½®ä¸­æ‰‹åŠ¨è®¾ç½® bot_qq ä»¥è·å¾—æ›´å¥½çš„ä½“éªŒ")
        from .license_validator import LicenseValidator
        if not license_token:
            logger.info("æœªé…ç½®æˆæƒTokenï¼Œè¿›å…¥è¯•ç”¨æ¨¡å¼...")
            try:
                validator = LicenseValidator(None)
                valid, msg = validator.validate_trial(bot_qq)
                if not valid:
                    raise Exception(f"âŒ {msg}\nğŸ’¡ è”ç³»å¼€å‘è€…è·å–æˆæƒTokenä»¥ç»§ç»­ä½¿ç”¨")
                logger.info(f"âœ“ {msg}")
                self._license_valid = True
                self._license_validator = validator
            except Exception as e:
                raise Exception(f"âŒ è¯•ç”¨éªŒè¯å¤±è´¥: {str(e)}")
        else:
            logger.info("æ­£åœ¨éªŒè¯æˆæƒToken...")
            try:
                validator = LicenseValidator(license_token)
                valid, msg = validator.validate(bot_qq)
                if not valid:
                    raise Exception(f"âŒ æˆæƒéªŒè¯å¤±è´¥: {msg}\nğŸ’¡ è¯·è”ç³»å¼€å‘è€…è·å–æˆ–ç»­è´¹æˆæƒ")
                logger.info(f"âœ“ {msg}")
                license_info = validator.get_license_info()
                if license_info:
                    user_info = license_info.get('user_info', 'æœªçŸ¥')
                    plan_type = license_info.get('plan_type', 'æœªçŸ¥')
                    expire_time = license_info.get('expire_time', 'æœªçŸ¥')
                    logger.info("ğŸ“‹ æˆæƒç”¨æˆ·: {}".format(user_info))
                    logger.info("ğŸ“¦ å¥—é¤ç±»å‹: {}".format(plan_type))
                    logger.info("ğŸ“… åˆ°æœŸæ—¶é—´: {}".format(expire_time))
                self._license_valid = True
                self._license_validator = validator
            except Exception as e:
                raise Exception(f"âŒ æˆæƒéªŒè¯å¼‚å¸¸: {str(e)}")
        if config is None:
            config = {}
        self.config = {
            'base_url': config.get('api_url', 'https://aliso.vip').rstrip('/'),
            'api_key': config.get('api_key', ''),
            'max_retries': config.get('max_retries', 3),
            'search_timeout': config.get('timeout', 10),
            'transfer_timeout': config.get('transfer_timeout', 30),
            'results_per_page': config.get('max_results', 5),
            'enable_transfer': config.get('enable_transfer', True),
            'transfer_delay': config.get('transfer_delay', 1),
            'log_level': 'INFO',
            'log_format': '%(asctime)s - %(name)s - %(levelname)s - %(message)s',
            'search_types': {
                'å¤¸å…‹': 0,
                'ç™¾åº¦': 2,
                'UC': 3,
                'è¿…é›·': 4
            },
            'search_commands': {
                'æœ': 'å¤¸å…‹',
                'ç™¾åº¦': 'ç™¾åº¦',
                'uc': 'UC',
                'UC': 'UC',
                'è¿…é›·': 'è¿…é›·'
            },
            'messages': {
                'searching': 'å…¨ç½‘æœç´¢ä¸­ï¼Œè¯·ç¨ç­‰ç‰‡åˆ»â€¦â€¦',
                'no_results': 'æœªæ‰¾åˆ°ç›¸å…³èµ„æº',
                'search_error': 'æœç´¢è¿‡ç¨‹ä¸­å‘ç”Ÿé”™è¯¯ï¼Œè¯·ç¨åé‡è¯•',
                'transfer_success': 'âœ… è½¬å­˜æˆåŠŸï¼\nğŸ“ èµ„æºæ ‡é¢˜ï¼š{0}\nğŸ”— åˆ†äº«é“¾æ¥ï¼š{1}',
                'transfer_disabled': 'âŒ è½¬å­˜åŠŸèƒ½æœªå¯ç”¨',
                'api_key_required': 'âŒ éœ€è¦é…ç½®APIå¯†é’¥æ‰èƒ½ä½¿ç”¨è½¬å­˜åŠŸèƒ½',
                'baidu_format_error': 'æŒ‡ä»¤æ ¼å¼é”™è¯¯ï¼Œè¯·ä½¿ç”¨ï¼šç™¾åº¦èµ„æºåç§°',
                'baidu_example': 'è¯·è¾“å…¥è¦æœç´¢çš„èµ„æºåç§°ï¼Œä¾‹å¦‚ï¼šç™¾åº¦{0}',
                'uc_format_error': 'æŒ‡ä»¤æ ¼å¼é”™è¯¯ï¼Œè¯·ä½¿ç”¨ï¼šucèµ„æºåç§°',
                'uc_example': 'è¯·è¾“å…¥è¦æœç´¢çš„èµ„æºåç§°ï¼Œä¾‹å¦‚ï¼šuc{0}',
                'uc_upper_format_error': 'æŒ‡ä»¤æ ¼å¼é”™è¯¯ï¼Œè¯·ä½¿ç”¨ï¼šUCèµ„æºåç§°',
                'uc_upper_example': 'è¯·è¾“å…¥è¦æœç´¢çš„èµ„æºåç§°ï¼Œä¾‹å¦‚ï¼šUC{0}',
                'xunlei_format_error': 'æŒ‡ä»¤æ ¼å¼é”™è¯¯ï¼Œè¯·ä½¿ç”¨ï¼šè¿…é›·èµ„æºåç§°',
                'xunlei_example': 'è¯·è¾“å…¥è¦æœç´¢çš„èµ„æºåç§°ï¼Œä¾‹å¦‚ï¼šè¿…é›·{0}',
                'last_page': 'å·²ç»æ˜¯æœ€åä¸€é¡µäº†',
                'no_search_session': 'æ²¡æœ‰æ‰¾åˆ°æœç´¢ä¼šè¯ï¼Œè¯·å…ˆè¿›è¡Œæœç´¢',
                'next_page_error': 'è·å–ä¸‹ä¸€é¡µå¤±è´¥ï¼Œè¯·ç¨åé‡è¯•',
                'first_page': 'å·²ç»æ˜¯ç¬¬ä¸€é¡µäº†',
                'previous_page_error': 'è·å–ä¸Šä¸€é¡µå¤±è´¥ï¼Œè¯·ç¨åé‡è¯•',
                'invalid_transfer_command': 'âŒ æ— æ•ˆçš„è½¬å­˜æŒ‡ä»¤æ ¼å¼',
                'no_search_for_transfer': 'âŒ æ²¡æœ‰æ‰¾åˆ°å¯è½¬å­˜çš„æœç´¢ç»“æœ',
                'search_expired': 'âŒ æœç´¢ä¼šè¯å·²è¿‡æœŸï¼Œè¯·é‡æ–°æœç´¢',
                'invalid_resource_index': 'âŒ æ— æ•ˆçš„èµ„æºåºå·ï¼Œè¯·è¾“å…¥1-{0}ä¹‹é—´çš„æ•°å­—',
                'no_valid_link': 'âŒ è¯¥èµ„æºæ²¡æœ‰æœ‰æ•ˆçš„åˆ†äº«é“¾æ¥',
                'only_quark_support': 'âŒ ç›®å‰ä»…æ”¯æŒå¤¸å…‹ç½‘ç›˜è½¬å­˜',
                'transferring': 'æ­£åœ¨è½¬å­˜ã€Š{0}ã€‹ï¼Œè¯·ç¨å€™...',
                'transfer_error': 'âŒ è½¬å­˜å¤±è´¥ï¼Œè¯·ç¨åé‡è¯•',
                'empty_keyword': 'âŒ æœç´¢å…³é”®è¯ä¸èƒ½ä¸ºç©º',
                'keyword_too_long': 'âŒ æœç´¢å…³é”®è¯è¿‡é•¿ï¼ˆè¶…è¿‡100å­—ç¬¦ï¼‰',
                'parse_search_failed': 'âŒ è§£ææœç´¢ç»“æœå¤±è´¥',
                'too_many_requests': 'âŒ è¯·æ±‚è¿‡äºé¢‘ç¹ï¼Œè¯·ç¨åå†è¯•',
                'search_service_unavailable': 'âŒ æœç´¢æœåŠ¡å¼‚å¸¸ï¼ŒHTTPçŠ¶æ€ç ï¼š{0}',
                'search_timeout': 'âŒ æœç´¢è¶…æ—¶ï¼Œè¯·ç¨åé‡è¯•',
                'network_error': 'âŒ ç½‘ç»œé”™è¯¯ï¼Œè¯·æ£€æŸ¥ç½‘ç»œè¿æ¥',
                'unknown_search_error': 'âŒ æœç´¢å‘ç”ŸæœªçŸ¥é”™è¯¯ï¼š{0}',
                'search_service_unavailable_temporarily': 'æœåŠ¡æš‚æ—¶ä¸å¯ç”¨',
                'search_failed': 'æœç´¢å¤±è´¥',
                'full_network_search_results': 'ğŸ” å…¨ç½‘æœç´¢ç»“æœï¼š{0}\n\n',
                'api_key_not_configured': 'âŒ APIå¯†é’¥æœªé…ç½®ï¼Œè¯·è”ç³»ç®¡ç†å‘˜é…ç½®api_key',
                'search_command_format_error': 'æŒ‡ä»¤æ ¼å¼é”™è¯¯ï¼Œè¯·ä½¿ç”¨ï¼š{0}èµ„æºåç§°',
                'search_example_format': 'è¯·è¾“å…¥è¦æœç´¢çš„èµ„æºåç§°ï¼Œä¾‹å¦‚ï¼š{0}{1}',
                'search_unknown_error': '{0}æœç´¢è¿‡ç¨‹ä¸­å‘ç”ŸæœªçŸ¥é”™è¯¯ï¼Œè¯·ç¨åé‡è¯•',
                'keyword_empty_error': 'æœç´¢å…³é”®è¯ä¸èƒ½ä¸ºç©º',
                'keyword_too_long_error': 'æœç´¢å…³é”®è¯è¿‡é•¿ï¼Œè¯·ç¼©çŸ­åé‡è¯•',
                'search_no_results_format': 'æœªæ‰¾åˆ°ä¸\'{0}\'ç›¸å…³çš„èµ„æº',
                'search_too_many_requests': 'è¯·æ±‚è¿‡äºé¢‘ç¹ï¼Œè¯·ç¨åå†è¯•',
                'search_service_unavailable_format': 'æœç´¢æœåŠ¡æš‚æ—¶ä¸å¯ç”¨ï¼ŒHTTPçŠ¶æ€ç : {0}',
                'search_timeout_error': 'æœç´¢è¶…æ—¶ï¼Œè¯·ç¨åé‡è¯•',
                'network_connection_error': 'ç½‘ç»œè¿æ¥å¼‚å¸¸ï¼Œè¯·æ£€æŸ¥ç½‘ç»œåé‡è¯•',
                'search_service_temporarily_unavailable': 'æœç´¢æœåŠ¡æš‚æ—¶ä¸å¯ç”¨ï¼Œè¯·ç¨åé‡è¯•',
                'search_unknown_error_format': 'æœç´¢è¿‡ç¨‹ä¸­å‘ç”ŸæœªçŸ¥é”™è¯¯: {0}',
                'search_results_parse_failed': 'æœç´¢ç»“æœè§£æå¤±è´¥ï¼Œè¯·ç¨åé‡è¯•',
                'no_previous_search': 'æ‚¨è¿˜æ²¡æœ‰è¿›è¡Œæœç´¢ï¼Œè¯·å…ˆä½¿ç”¨æœç´¢æŒ‡ä»¤ï¼Œä¾‹å¦‚ï¼š\næœç”µå½±å\nç™¾åº¦ç”µå½±å\nucç”µå½±å\nè¿…é›·ç”µå½±å',
                'next_page_unknown_error': 'å¤„ç†ä¸‹ä¸€é¡µæŒ‡ä»¤æ—¶å‘ç”ŸæœªçŸ¥é”™è¯¯ï¼Œè¯·ç¨åé‡è¯•',
                'previous_page_unknown_error': 'å¤„ç†ä¸Šä¸€é¡µæŒ‡ä»¤æ—¶å‘ç”ŸæœªçŸ¥é”™è¯¯ï¼Œè¯·ç¨åé‡è¯•',
                'transfer_failed': 'âŒ è½¬å­˜å¤±è´¥ï¼š{0}',
                'transfer_service_error': 'âŒ è½¬å­˜æœåŠ¡å¼‚å¸¸ï¼ŒHTTPçŠ¶æ€ç ï¼š{0}',
                'transfer_timeout': 'âŒ è½¬å­˜è¶…æ—¶ï¼Œè¯·ç¨åé‡è¯•',
                'transfer_process_error': 'âŒ è½¬å­˜è¿‡ç¨‹ä¸­å‘ç”Ÿé”™è¯¯ï¼š{0}',
                'show_config_error': 'æ˜¾ç¤ºé…ç½®ä¿¡æ¯æ—¶å‘ç”Ÿé”™è¯¯',
                'unknown_error': 'æœªçŸ¥é”™è¯¯',
                'invalid_page_number': 'âŒ é¡µç è¶…å‡ºèŒƒå›´ï¼Œæ€»é¡µæ•°ä¸º{0}',
                'format_search_error': 'âŒ æ ¼å¼åŒ–æœç´¢ç»“æœå¤±è´¥',
                'resource_title_default': 'æœªçŸ¥æ ‡é¢˜',
                'resource_link_format': '{0}. {1}\né“¾æ¥: `{2}`',
                'resource_title_format': '{0}. {1}',
                'quark_transfer_prompt': 'ğŸ’¡ å›å¤"è½¬å­˜{0}"å¯è½¬å­˜åˆ°å¤¸å…‹ç½‘ç›˜',
                'search_results_header': 'ğŸ” å…±æ‰¾åˆ° {0} ä¸ªç›¸å…³èµ„æºï¼š',
                'search_results_separator': 'â”€' * 14,
                'search_results_footer': 'é“¾æ¥æœ‰æ•ˆæœŸ5åˆ†é’Ÿï¼Œè¿‡æœŸè¯·é‡æœ',
                'search_results_separator_footer': 'â”€' * 14,
                'search_results_website_promo': 'æ›´å¤šèµ„æºè¯·ä¸Š {0}',
                'search_results_page_info': 'ğŸ“„ ç¬¬ {0}/{1} é¡µ',
                'search_results_navigation': 'ğŸ’¡ å›å¤"ä¸Š/ä¸‹"æˆ–"0/1"ç¿»é¡µ',
                'no_resources_found': 'æœªæ‰¾åˆ°ç›¸å…³èµ„æº: {0}\n\nğŸ’¡ æç¤ºï¼šè¯·å°è¯•å…¶ä»–ç½‘ç›˜æœç´¢'
            }
        }
        self.base_url = self.config['base_url']
        self.api_key = self.config['api_key']
        self.max_retries = self.config['max_retries']
        self.search_timeout = self.config['search_timeout']
        self.transfer_timeout = self.config['transfer_timeout']
        self.results_per_page = self.config['results_per_page']
        self.enable_transfer = self.config['enable_transfer']
        self.enable_pagination = config.get('enable_pagination', True)
        self.transfer_delay = self.config['transfer_delay']
        self.search_types = self.config['search_types']
        self.search_commands = self.config['search_commands']
        self.messages = self.config['messages']
        self.rate_limiter = RateLimiter(max_requests=10, window_seconds=60)
        self.user_sessions: Dict[str, Dict] = {}
        self._cookie_cache: Dict[str, tuple] = {}
    def _load_config(self) -> dict:
        config_file = os.path.join(os.path.dirname(__file__), 'config.yaml')
        default_config = {
            'base_url': 'https://aliso.vip',
            'api_key': '',
            'max_retries': 3,
            'search_timeout': 10,
            'transfer_timeout': 30,
            'results_per_page': 5,
            'enable_transfer': True,
            'transfer_delay': 1,
            'log_level': 'INFO',
            'messages': {
                'searching': 'å…¨ç½‘æœç´¢ä¸­ï¼Œè¯·ç¨ç­‰ç‰‡åˆ»â€¦â€¦',
                'no_results': 'æœªæ‰¾åˆ°ç›¸å…³èµ„æº',
                'search_error': 'æœç´¢è¿‡ç¨‹ä¸­å‘ç”Ÿé”™è¯¯ï¼Œè¯·ç¨åé‡è¯•',
                'transfer_success': 'âœ… è½¬å­˜æˆåŠŸï¼\nğŸ“ èµ„æºæ ‡é¢˜ï¼š{0}\nğŸ”— åˆ†äº«é“¾æ¥ï¼š{1}',
                'transfer_disabled': 'âŒ è½¬å­˜åŠŸèƒ½æœªå¯ç”¨',
                'api_key_required': 'âŒ éœ€è¦é…ç½®APIå¯†é’¥æ‰èƒ½ä½¿ç”¨è½¬å­˜åŠŸèƒ½',
                'baidu_format_error': 'æŒ‡ä»¤æ ¼å¼é”™è¯¯ï¼Œè¯·ä½¿ç”¨ï¼šç™¾åº¦èµ„æºåç§°',
                'baidu_example': 'è¯·è¾“å…¥è¦æœç´¢çš„èµ„æºåç§°ï¼Œä¾‹å¦‚ï¼šç™¾åº¦{0}',
                'uc_format_error': 'æŒ‡ä»¤æ ¼å¼é”™è¯¯ï¼Œè¯·ä½¿ç”¨ï¼šucèµ„æºåç§°',
                'uc_example': 'è¯·è¾“å…¥è¦æœç´¢çš„èµ„æºåç§°ï¼Œä¾‹å¦‚ï¼šuc{0}',
                'uc_upper_format_error': 'æŒ‡ä»¤æ ¼å¼é”™è¯¯ï¼Œè¯·ä½¿ç”¨ï¼šUCèµ„æºåç§°',
                'uc_upper_example': 'è¯·è¾“å…¥è¦æœç´¢çš„èµ„æºåç§°ï¼Œä¾‹å¦‚ï¼šUC{0}',
                'xunlei_format_error': 'æŒ‡ä»¤æ ¼å¼é”™è¯¯ï¼Œè¯·ä½¿ç”¨ï¼šè¿…é›·èµ„æºåç§°',
                'xunlei_example': 'è¯·è¾“å…¥è¦æœç´¢çš„èµ„æºåç§°ï¼Œä¾‹å¦‚ï¼šè¿…é›·{0}',
                'last_page': 'å·²ç»æ˜¯æœ€åä¸€é¡µäº†',
                'no_search_session': 'æ²¡æœ‰æ‰¾åˆ°æœç´¢ä¼šè¯ï¼Œè¯·å…ˆè¿›è¡Œæœç´¢',
                'next_page_error': 'è·å–ä¸‹ä¸€é¡µå¤±è´¥ï¼Œè¯·ç¨åé‡è¯•',
                'first_page': 'å·²ç»æ˜¯ç¬¬ä¸€é¡µäº†',
                'previous_page_error': 'è·å–ä¸Šä¸€é¡µå¤±è´¥ï¼Œè¯·ç¨åé‡è¯•',
                'invalid_transfer_command': 'âŒ æ— æ•ˆçš„è½¬å­˜æŒ‡ä»¤æ ¼å¼',
                'no_search_for_transfer': 'âŒ æ²¡æœ‰æ‰¾åˆ°å¯è½¬å­˜çš„æœç´¢ç»“æœ',
                'search_expired': 'âŒ æœç´¢ä¼šè¯å·²è¿‡æœŸï¼Œè¯·é‡æ–°æœç´¢',
                'invalid_resource_index': 'âŒ æ— æ•ˆçš„èµ„æºåºå·ï¼Œè¯·è¾“å…¥1-{0}ä¹‹é—´çš„æ•°å­—',
                'no_valid_link': 'âŒ è¯¥èµ„æºæ²¡æœ‰æœ‰æ•ˆçš„åˆ†äº«é“¾æ¥',
                'only_quark_support': 'âŒ ç›®å‰ä»…æ”¯æŒå¤¸å…‹ç½‘ç›˜è½¬å­˜',
                'transferring': 'æ­£åœ¨è½¬å­˜ã€Š{0}ã€‹ï¼Œè¯·ç¨å€™...',
                'transfer_error': 'âŒ è½¬å­˜å¤±è´¥ï¼Œè¯·ç¨åé‡è¯•',
                'empty_keyword': 'âŒ æœç´¢å…³é”®è¯ä¸èƒ½ä¸ºç©º',
                'keyword_too_long': 'âŒ æœç´¢å…³é”®è¯è¿‡é•¿ï¼ˆè¶…è¿‡100å­—ç¬¦ï¼‰',
                'parse_search_failed': 'âŒ è§£ææœç´¢ç»“æœå¤±è´¥',
                'too_many_requests': 'âŒ è¯·æ±‚è¿‡äºé¢‘ç¹ï¼Œè¯·ç¨åå†è¯•',
                'search_service_unavailable': 'âŒ æœç´¢æœåŠ¡å¼‚å¸¸ï¼ŒHTTPçŠ¶æ€ç ï¼š{0}',
                'search_timeout': 'âŒ æœç´¢è¶…æ—¶ï¼Œè¯·ç¨åé‡è¯•',
                'network_error': 'âŒ ç½‘ç»œé”™è¯¯ï¼Œè¯·æ£€æŸ¥ç½‘ç»œè¿æ¥',
                'unknown_search_error': 'âŒ æœç´¢å‘ç”ŸæœªçŸ¥é”™è¯¯ï¼š{0}',
                'search_service_unavailable_temporarily': 'æœåŠ¡æš‚æ—¶ä¸å¯ç”¨',
                'search_failed': 'æœç´¢å¤±è´¥',
                'full_network_search_results': 'ğŸ” å…¨ç½‘æœç´¢ç»“æœï¼š{0}\n\n',
                'api_key_not_configured': 'âŒ APIå¯†é’¥æœªé…ç½®ï¼Œè¯·è”ç³»ç®¡ç†å‘˜é…ç½®api_key',
                'search_command_format_error': 'æŒ‡ä»¤æ ¼å¼é”™è¯¯ï¼Œè¯·ä½¿ç”¨ï¼š{0}èµ„æºåç§°',
                'search_example_format': 'è¯·è¾“å…¥è¦æœç´¢çš„èµ„æºåç§°ï¼Œä¾‹å¦‚ï¼š{0}{1}',
                'search_unknown_error': '{0}æœç´¢è¿‡ç¨‹ä¸­å‘ç”ŸæœªçŸ¥é”™è¯¯ï¼Œè¯·ç¨åé‡è¯•',
                'keyword_empty_error': 'æœç´¢å…³é”®è¯ä¸èƒ½ä¸ºç©º',
                'keyword_too_long_error': 'æœç´¢å…³é”®è¯è¿‡é•¿ï¼Œè¯·ç¼©çŸ­åé‡è¯•',
                'search_no_results_format': 'æœªæ‰¾åˆ°ä¸\'{0}\'ç›¸å…³çš„èµ„æº',
                'search_too_many_requests': 'è¯·æ±‚è¿‡äºé¢‘ç¹ï¼Œè¯·ç¨åå†è¯•',
                'search_service_unavailable_format': 'æœç´¢æœåŠ¡æš‚æ—¶ä¸å¯ç”¨ï¼ŒHTTPçŠ¶æ€ç : {0}',
                'search_timeout_error': 'æœç´¢è¶…æ—¶ï¼Œè¯·ç¨åé‡è¯•',
                'network_connection_error': 'ç½‘ç»œè¿æ¥å¼‚å¸¸ï¼Œè¯·æ£€æŸ¥ç½‘ç»œåé‡è¯•',
                'search_service_temporarily_unavailable': 'æœç´¢æœåŠ¡æš‚æ—¶ä¸å¯ç”¨ï¼Œè¯·ç¨åé‡è¯•',
                'search_unknown_error_format': 'æœç´¢è¿‡ç¨‹ä¸­å‘ç”ŸæœªçŸ¥é”™è¯¯: {0}',
                'search_results_parse_failed': 'æœç´¢ç»“æœè§£æå¤±è´¥ï¼Œè¯·ç¨åé‡è¯•',
                'no_previous_search': 'æ‚¨è¿˜æ²¡æœ‰è¿›è¡Œæœç´¢ï¼Œè¯·å…ˆä½¿ç”¨æœç´¢æŒ‡ä»¤ï¼Œä¾‹å¦‚ï¼š\næœç”µå½±å\nç™¾åº¦ç”µå½±å\nucç”µå½±å\nè¿…é›·ç”µå½±å',
                'next_page_unknown_error': 'å¤„ç†ä¸‹ä¸€é¡µæŒ‡ä»¤æ—¶å‘ç”ŸæœªçŸ¥é”™è¯¯ï¼Œè¯·ç¨åé‡è¯•',
                'previous_page_unknown_error': 'å¤„ç†ä¸Šä¸€é¡µæŒ‡ä»¤æ—¶å‘ç”ŸæœªçŸ¥é”™è¯¯ï¼Œè¯·ç¨åé‡è¯•',
                'transfer_failed': 'âŒ è½¬å­˜å¤±è´¥ï¼š{0}',
                'transfer_service_error': 'âŒ è½¬å­˜æœåŠ¡å¼‚å¸¸ï¼ŒHTTPçŠ¶æ€ç ï¼š{0}',
                'transfer_timeout': 'âŒ è½¬å­˜è¶…æ—¶ï¼Œè¯·ç¨åé‡è¯•',
                'transfer_process_error': 'âŒ è½¬å­˜è¿‡ç¨‹ä¸­å‘ç”Ÿé”™è¯¯ï¼š{0}',
                'show_config_error': 'æ˜¾ç¤ºé…ç½®ä¿¡æ¯æ—¶å‘ç”Ÿé”™è¯¯',
                'unknown_error': 'æœªçŸ¥é”™è¯¯',
                'invalid_page_number': 'âŒ é¡µç è¶…å‡ºèŒƒå›´ï¼Œæ€»é¡µæ•°ä¸º{0}',
                'format_search_error': 'âŒ æ ¼å¼åŒ–æœç´¢ç»“æœå¤±è´¥',
                'resource_title_default': 'æœªçŸ¥æ ‡é¢˜',
                'resource_link_format': '{0}. {1}\né“¾æ¥: `{2}`',
                'resource_title_format': '{0}. {1}',
                'quark_transfer_prompt': 'ğŸ’¡ å›å¤"è½¬å­˜{0}"å¯è½¬å­˜åˆ°å¤¸å…‹ç½‘ç›˜',
                'search_results_header': 'ğŸ” å…±æ‰¾åˆ° {0} ä¸ªç›¸å…³èµ„æºï¼š',
                'search_results_separator': 'â”€' * 20,
                'search_results_footer': 'é“¾æ¥æœ‰æ•ˆæœŸ5åˆ†é’Ÿï¼Œè¿‡æœŸè¯·é‡æœ',
                'search_results_separator_footer': 'â”€' * 20,
                'search_results_page_info': 'ğŸ“„ ç¬¬ {0}/{1} é¡µ',
                'search_results_navigation': 'ğŸ’¡ å›å¤"ä¸Š/ä¸‹"æˆ–"0/1"ç¿»é¡µ',
                'no_resources_found': 'æœªæ‰¾åˆ°ç›¸å…³èµ„æº: {0}\n\nğŸ’¡ æç¤ºï¼šè¯·å°è¯•å…¶ä»–ç½‘ç›˜æœç´¢'
            }
        }
        try:
            if os.path.exists(config_file):
                with open(config_file, 'r', encoding='utf-8') as f:
                    config = yaml.safe_load(f)
                    if config:
                        for key, value in config.items():
                            if key == 'messages' and isinstance(value, dict):
                                if 'messages' in default_config:
                                    default_config['messages'].update(value)
                                else:
                                    default_config['messages'] = value
                            else:
                                default_config[key] = value
                        logger.info("é…ç½®æ–‡ä»¶åŠ è½½æˆåŠŸ")
                    else:
                        logger.warning("é…ç½®æ–‡ä»¶ä¸ºç©ºï¼Œä½¿ç”¨é»˜è®¤é…ç½®")
            else:
                logger.warning("é…ç½®æ–‡ä»¶ä¸å­˜åœ¨ï¼Œä½¿ç”¨é»˜è®¤é…ç½®")
                with open(config_file, 'w', encoding='utf-8') as f:
                    yaml.dump(default_config, f,
                              default_flow_style=False, allow_unicode=True)
                logger.info("å·²åˆ›å»ºé»˜è®¤é…ç½®æ–‡ä»¶")
        except Exception as e:
            logger.error(f"åŠ è½½é…ç½®æ–‡ä»¶å¤±è´¥: {str(e)}ï¼Œä½¿ç”¨é»˜è®¤é…ç½®")
        return default_config
    async def initialize(self):
        logger.info("å¿ƒæ‚¦æœç´¢æ’ä»¶å·²åŠ è½½")
        logger.info(f"åŸºç¡€URL: {self.base_url}")
        logger.info(f"è½¬å­˜åŠŸèƒ½: {'å·²å¯ç”¨' if self.enable_transfer else 'å·²ç¦ç”¨'}")
        if self.api_key:
            logger.info("APIå¯†é’¥: å·²é…ç½®")
    def _check_license(self):
        if not hasattr(self, '_license_valid'):
            raise Exception("âŒ æˆæƒæœªåˆå§‹åŒ–ï¼Œè¯·é‡å¯æ’ä»¶")
        if not self._license_valid:
            raise Exception("âŒ æˆæƒå·²å¤±æ•ˆï¼Œè¯·è”ç³»å¼€å‘è€…")
        else:
            logger.warning("APIå¯†é’¥: æœªé…ç½®ï¼Œè½¬å­˜åŠŸèƒ½å¯èƒ½æ— æ³•æ­£å¸¸å·¥ä½œ")
    def _get_user_session_key(self, event: AstrMessageEvent) -> str:
        try:
            user_id = None
            if hasattr(event, 'message_obj') and event.message_obj:
                if hasattr(event.message_obj, 'sender') and event.message_obj.sender:
                    user_id = event.message_obj.sender.user_id
            if user_id:
                group_id = event.message_obj.group_id if hasattr(event.message_obj, 'group_id') else event.session_id
                return f"{user_id}@{group_id}"
            logger.warning("æ— æ³•è·å–ç”¨æˆ·IDï¼Œä½¿ç”¨unified_msg_originä½œä¸ºä¼šè¯key")
            return event.unified_msg_origin
        except Exception as e:
            logger.error(f"è·å–ç”¨æˆ·ä¼šè¯keyæ—¶å‘ç”Ÿé”™è¯¯: {str(e)}")
            return event.unified_msg_origin
    def _format_reply_with_mention(self, event: AstrMessageEvent, message: str) -> str:
        return message
    def _get_user_id_for_rate_limit(self, event: AstrMessageEvent) -> str:
        try:
            if hasattr(event, 'message_obj') and event.message_obj:
                if hasattr(event.message_obj, 'sender') and event.message_obj.sender:
                    return str(event.message_obj.sender.user_id)
            logger.warning("æ— æ³•è·å–ç”¨æˆ·IDç”¨äºé™æµï¼Œä½¿ç”¨unified_msg_origin")
            return event.unified_msg_origin
        except Exception as e:
            logger.error(f"è·å–ç”¨æˆ·IDç”¨äºé™æµæ—¶å‘ç”Ÿé”™è¯¯: {str(e)}")
            return event.unified_msg_origin
    @filter.regex(r"^æœ(\s+|(?![ç´¢]).)\S+")
    async def search_resource(self, event: AstrMessageEvent, *args, **kwargs):
        try:
            user_session_key = self._get_user_session_key(event)
            user_id_for_limit = self._get_user_id_for_rate_limit(event)
            if not self.rate_limiter.is_allowed(user_id_for_limit):
                wait_time = self.rate_limiter.get_wait_time(user_id_for_limit)
                yield event.plain_result(f"âŒ è¯·æ±‚è¿‡äºé¢‘ç¹ï¼Œè¯·{wait_time}ç§’åå†è¯•")
                return
            message = event.message_str.strip()
            if message.startswith("æœ"):
                keyword = message[1:].strip()
            else:
                yield event.plain_result(self.messages['search_command_format_error'].format(self.search_commands['æœ']))
                return
            if not keyword:
                yield event.plain_result(self.messages['search_example_format'].format(self.search_commands['æœ'], 'ç”µå½±å'))
                return
            yield event.plain_result(self._format_reply_with_mention(event, self.messages['searching']))
            result = await self._search_resources(user_session_key, keyword, is_full_network=False, pan_type=0)
            yield event.plain_result(self._format_reply_with_mention(event, result))
        except Exception as e:
            logger.error(f"æœç´¢èµ„æºæ—¶å‘ç”Ÿé”™è¯¯: {str(e)}")
            yield event.plain_result(self.messages['search_error'])
    @filter.regex(r"^æ‰¾\s*\S+")
    async def local_search(self, event: AstrMessageEvent):
        try:
            user_session_key = self._get_user_session_key(event)
            user_id_for_limit = self._get_user_id_for_rate_limit(event)
            if not self.rate_limiter.is_allowed(user_id_for_limit):
                wait_time = self.rate_limiter.get_wait_time(user_id_for_limit)
                yield event.plain_result(f"âŒ è¯·æ±‚è¿‡äºé¢‘ç¹ï¼Œè¯·{wait_time}ç§’åå†è¯•")
                return
            message = event.message_str.strip()
            if message.startswith("æ‰¾"):
                keyword = message[1:].strip()
            else:
                yield event.plain_result("æŒ‡ä»¤æ ¼å¼é”™è¯¯ï¼Œè¯·ä½¿ç”¨ï¼šæ‰¾èµ„æºåç§°")
                return
            if not keyword:
                yield event.plain_result("è¯·è¾“å…¥è¦æŸ¥æ‰¾çš„èµ„æºåç§°ï¼Œä¾‹å¦‚ï¼šæ‰¾ç”µå½±å")
                return
            yield event.plain_result(self._format_reply_with_mention(event, "ğŸ” æ­£åœ¨æœ¬åœ°æ•°æ®åº“æŸ¥æ‰¾ï¼Œè¯·ç¨å€™..."))
            result = await self._local_search(keyword)
            yield event.plain_result(self._format_reply_with_mention(event, result))
        except Exception as e:
            logger.error(f"æœ¬åœ°æœç´¢æ—¶å‘ç”Ÿé”™è¯¯: {str(e)}")
            yield event.plain_result("âŒ æœç´¢è¿‡ç¨‹ä¸­å‘ç”Ÿé”™è¯¯ï¼Œè¯·ç¨åé‡è¯•")
    @filter.regex(r"^ç™¾åº¦\s*\S+")
    async def baidu_search(self, event: AstrMessageEvent):
        try:
            user_session_key = self._get_user_session_key(event)
            user_id_for_limit = self._get_user_id_for_rate_limit(event)
            if not self.rate_limiter.is_allowed(user_id_for_limit):
                wait_time = self.rate_limiter.get_wait_time(user_id_for_limit)
                yield event.plain_result(f"âŒ è¯·æ±‚è¿‡äºé¢‘ç¹ï¼Œè¯·{wait_time}ç§’åå†è¯•")
                return
            message = event.message_str.strip()
            if message.startswith("ç™¾åº¦"):
                keyword = message[2:].strip()
            else:
                yield event.plain_result(self.messages['baidu_format_error'])
                return
            if not keyword:
                yield event.plain_result(self.messages['baidu_example'].format('ç”µå½±å'))
                return
            yield event.plain_result(self._format_reply_with_mention(event, self.messages['searching']))
            result = await self._search_resources(user_session_key, keyword, is_full_network=False, pan_type=2)
            yield event.plain_result(self._format_reply_with_mention(event, result))
        except Exception as e:
            logger.error(f"ç™¾åº¦æœç´¢æ—¶å‘ç”Ÿé”™è¯¯: {str(e)}")
            yield event.plain_result(self.messages['search_error'])
    @filter.regex(r"^uc\s*\S+")
    async def uc_search_lower(self, event: AstrMessageEvent):
        try:
            user_session_key = self._get_user_session_key(event)
            user_id_for_limit = self._get_user_id_for_rate_limit(event)
            if not self.rate_limiter.is_allowed(user_id_for_limit):
                wait_time = self.rate_limiter.get_wait_time(user_id_for_limit)
                yield event.plain_result(f"âŒ è¯·æ±‚è¿‡äºé¢‘ç¹ï¼Œè¯·{wait_time}ç§’åå†è¯•")
                return
            message = event.message_str.strip()
            if message.startswith("uc"):
                keyword = message[2:].strip()
            else:
                yield event.plain_result(self.messages['uc_format_error'])
                return
            if not keyword:
                yield event.plain_result(self.messages['uc_example'].format('ç”µå½±å'))
                return
            yield event.plain_result(self._format_reply_with_mention(event, self.messages['searching']))
            result = await self._search_resources(user_session_key, keyword, is_full_network=False, pan_type=3)
            yield event.plain_result(self._format_reply_with_mention(event, result))
        except Exception as e:
            logger.error(f"UCæœç´¢æ—¶å‘ç”Ÿé”™è¯¯: {str(e)}")
            yield event.plain_result(self.messages['search_error'])
    @filter.regex(r"^UC\s*\S+")
    async def uc_search_upper(self, event: AstrMessageEvent):
        try:
            user_session_key = self._get_user_session_key(event)
            user_id_for_limit = self._get_user_id_for_rate_limit(event)
            if not self.rate_limiter.is_allowed(user_id_for_limit):
                wait_time = self.rate_limiter.get_wait_time(user_id_for_limit)
                yield event.plain_result(f"âŒ è¯·æ±‚è¿‡äºé¢‘ç¹ï¼Œè¯·{wait_time}ç§’åå†è¯•")
                return
            message = event.message_str.strip()
            if message.startswith("UC"):
                keyword = message[2:].strip()
            else:
                yield event.plain_result(self.messages['uc_upper_format_error'])
                return
            if not keyword:
                yield event.plain_result(self.messages['uc_upper_example'].format('ç”µå½±å'))
                return
            yield event.plain_result(self._format_reply_with_mention(event, self.messages['searching']))
            result = await self._search_resources(user_session_key, keyword, is_full_network=False, pan_type=3)
            yield event.plain_result(self._format_reply_with_mention(event, result))
        except Exception as e:
            logger.error(f"UCæœç´¢æ—¶å‘ç”Ÿé”™è¯¯: {str(e)}")
            yield event.plain_result(self.messages['search_error'])
    @filter.regex(r"^è¿…é›·\s*\S+")
    async def xunlei_search(self, event: AstrMessageEvent):
        try:
            user_session_key = self._get_user_session_key(event)
            user_id_for_limit = self._get_user_id_for_rate_limit(event)
            if not self.rate_limiter.is_allowed(user_id_for_limit):
                wait_time = self.rate_limiter.get_wait_time(user_id_for_limit)
                yield event.plain_result(f"âŒ è¯·æ±‚è¿‡äºé¢‘ç¹ï¼Œè¯·{wait_time}ç§’åå†è¯•")
                return
            message = event.message_str.strip()
            if message.startswith("è¿…é›·"):
                keyword = message[2:].strip()
            else:
                yield event.plain_result(self.messages['xunlei_format_error'])
                return
            if not keyword:
                yield event.plain_result(self.messages['xunlei_example'].format('ç”µå½±å'))
                return
            yield event.plain_result(self._format_reply_with_mention(event, self.messages['searching']))
            result = await self._search_resources(user_session_key, keyword, is_full_network=False, pan_type=4)
            yield event.plain_result(self._format_reply_with_mention(event, result))
        except Exception as e:
            logger.error(f"è¿…é›·æœç´¢æ—¶å‘ç”Ÿé”™è¯¯: {str(e)}")
            yield event.plain_result(self.messages['search_error'])
    @filter.regex(r"^1$")
    async def next_page(self, event: AstrMessageEvent):
        try:
            if not self.enable_pagination:
                return
            user_session_key = self._get_user_session_key(event)
            if user_session_key in self.user_sessions and 'results' in self.user_sessions[user_session_key]:
                session_data = self.user_sessions[user_session_key]
                results = session_data.get('results')
                if not results:
                    return
                current_page = session_data.get('current_page', 1)
                total_pages = session_data.get('total_pages', 1)
                if total_pages <= 1:
                    return
                keyword = session_data.get('keyword', '')
                is_full_network = session_data.get('is_full_network', False)
                pan_type = session_data.get('pan_type', 0)
                if current_page < total_pages:
                    yield event.plain_result(self._format_reply_with_mention(event, "â³ æ­£åœ¨ç¿»é¡µï¼Œè¯·ç¨å€™..."))
                    next_page = current_page + 1
                    self.user_sessions[user_session_key]['current_page'] = next_page
                    result = await self._format_search_results(user_session_key, results, keyword, is_full_network, next_page)
                    yield event.plain_result(self._format_reply_with_mention(event, result))
                else:
                    yield event.plain_result(self._format_reply_with_mention(event, self.messages['last_page']))
        except Exception as e:
            logger.error(f"å¤„ç†ä¸‹ä¸€é¡µæŒ‡ä»¤æ—¶å‘ç”Ÿé”™è¯¯: {str(e)}")
            yield event.plain_result(self.messages['next_page_error'])
    @filter.regex(r"^0$")
    async def previous_page(self, event: AstrMessageEvent):
        try:
            if not self.enable_pagination:
                return
            user_session_key = self._get_user_session_key(event)
            if user_session_key in self.user_sessions and 'results' in self.user_sessions[user_session_key]:
                session_data = self.user_sessions[user_session_key]
                results = session_data.get('results')
                if not results:
                    return
                current_page = session_data.get('current_page', 1)
                total_pages = session_data.get('total_pages', 1)
                if total_pages <= 1:
                    return
                keyword = session_data.get('keyword', '')
                is_full_network = session_data.get('is_full_network', False)
                pan_type = session_data.get('pan_type', 0)
                if current_page > 1:
                    yield event.plain_result(self._format_reply_with_mention(event, "â³ æ­£åœ¨ç¿»é¡µï¼Œè¯·ç¨å€™..."))
                    previous_page = current_page - 1
                    self.user_sessions[user_session_key]['current_page'] = previous_page
                    result = await self._format_search_results(user_session_key, results, keyword, is_full_network, previous_page)
                    yield event.plain_result(self._format_reply_with_mention(event, result))
                else:
                    yield event.plain_result(self._format_reply_with_mention(event, self.messages['first_page']))
        except Exception as e:
            logger.error(f"å¤„ç†ä¸Šä¸€é¡µæŒ‡ä»¤æ—¶å‘ç”Ÿé”™è¯¯: {str(e)}")
            yield event.plain_result(self.messages['previous_page_error'])
    @filter.regex(r"^ä¸‹$")
    async def next_page_simple(self, event: AstrMessageEvent):
        try:
            if not self.enable_pagination:
                return
            user_session_key = self._get_user_session_key(event)
            if user_session_key in self.user_sessions and 'results' in self.user_sessions[user_session_key]:
                session_data = self.user_sessions[user_session_key]
                results = session_data.get('results')
                if not results:
                    return
                current_page = session_data.get('current_page', 1)
                total_pages = session_data.get('total_pages', 1)
                if total_pages <= 1:
                    return
                keyword = session_data.get('keyword', '')
                is_full_network = session_data.get('is_full_network', False)
                pan_type = session_data.get('pan_type', 0)
                if current_page < total_pages:
                    yield event.plain_result(self._format_reply_with_mention(event, "â³ æ­£åœ¨ç¿»é¡µï¼Œè¯·ç¨å€™..."))
                    next_page = current_page + 1
                    self.user_sessions[user_session_key]['current_page'] = next_page
                    result = await self._format_search_results(user_session_key, results, keyword, is_full_network, next_page)
                    yield event.plain_result(self._format_reply_with_mention(event, result))
                else:
                    yield event.plain_result(self._format_reply_with_mention(event, self.messages['last_page']))
        except Exception as e:
            logger.error(f"å¤„ç†ä¸‹ä¸€é¡µæŒ‡ä»¤æ—¶å‘ç”Ÿé”™è¯¯: {str(e)}")
            yield event.plain_result(self.messages['next_page_error'])
    @filter.regex(r"^ä¸Š$")
    async def previous_page_simple(self, event: AstrMessageEvent):
        try:
            if not self.enable_pagination:
                return
            user_session_key = self._get_user_session_key(event)
            if user_session_key in self.user_sessions and 'results' in self.user_sessions[user_session_key]:
                session_data = self.user_sessions[user_session_key]
                results = session_data.get('results')
                if not results:
                    return
                current_page = session_data.get('current_page', 1)
                total_pages = session_data.get('total_pages', 1)
                if total_pages <= 1:
                    return
                keyword = session_data.get('keyword', '')
                is_full_network = session_data.get('is_full_network', False)
                pan_type = session_data.get('pan_type', 0)
                if current_page > 1:
                    yield event.plain_result(self._format_reply_with_mention(event, "â³ æ­£åœ¨ç¿»é¡µï¼Œè¯·ç¨å€™..."))
                    previous_page = current_page - 1
                    self.user_sessions[user_session_key]['current_page'] = previous_page
                    result = await self._format_search_results(user_session_key, results, keyword, is_full_network, previous_page)
                    yield event.plain_result(self._format_reply_with_mention(event, result))
                else:
                    yield event.plain_result(self._format_reply_with_mention(event, self.messages['first_page']))
            else:
                yield event.plain_result(self.messages['no_search_session'])
        except Exception as e:
            logger.error(f"å¤„ç†ä¸Šä¸€é¡µæŒ‡ä»¤æ—¶å‘ç”Ÿé”™è¯¯: {str(e)}")
            yield event.plain_result(self.messages['previous_page_error'])
    @filter.regex(r"^è½¬å­˜(\d+)$")
    async def transfer_resource(self, event: AstrMessageEvent):
        try:
            if not self.enable_transfer:
                yield event.plain_result(self.messages['transfer_disabled'])
                return
            if not self.api_key:
                yield event.plain_result(self.messages['api_key_required'])
                return
            user_session_key = self._get_user_session_key(event)
            match = re.search(r"è½¬å­˜(\d+)", event.get_message_content())
            if not match:
                yield event.plain_result(self.messages['invalid_transfer_command'])
                return
            resource_index = int(match.group(1))
            if user_session_key not in self.user_sessions or 'results' not in self.user_sessions[user_session_key]:
                yield event.plain_result(self.messages['no_search_for_transfer'])
                return
            session_data = self.user_sessions[user_session_key]
            current_page = session_data.get('current_page', 1)
            results = session_data['results']
            result_list = []
            if isinstance(results, str) and session_data.get('is_sse', False):
                parsed_data = self._parse_sse_response(
                    results, session_data.get('keyword', ''), current_page)
                if isinstance(parsed_data, list):
                    result_list = parsed_data
            elif isinstance(results, dict):
                if 'result' in results:
                    result_list = results['result']
                elif 'data' in results:
                    result_list = results['data']
                elif 'list' in results:
                    result_list = results['list']
            elif isinstance(results, list):
                result_list = results
            if not result_list:
                yield event.plain_result(self.messages['search_expired'])
                return
            page_size = 5
            start_index = (current_page - 1) * page_size
            if resource_index < 1 or resource_index > len(result_list):
                yield event.plain_result(self.messages['invalid_resource_index'].format(len(result_list)))
                return
            target_resource = result_list[start_index + resource_index - 1]
            url = target_resource.get('url', '')
            title = target_resource.get('title', 'æœªçŸ¥æ ‡é¢˜')
            if not url:
                yield event.plain_result(self.messages['no_valid_link'])
                return
            supported_domains = ['pan.quark.cn', 'www.alipan.com', 'www.aliyundrive.com',
                                 'pan.baidu.com', 'drive.uc.cn', 'fast.uc.cn', 'pan.xunlei.com']
            is_supported = False
            lower_url = url.lower()
            for domain in supported_domains:
                if domain in lower_url:
                    is_supported = True
                    break
            if not is_supported:
                yield event.plain_result("âŒ æš‚ä¸æ”¯æŒè¯¥ç½‘ç›˜çš„è½¬å­˜åŠŸèƒ½")
                return
            yield event.plain_result(self.messages['transferring'].format(title))
            await asyncio.sleep(self.transfer_delay)
            transfer_result = await self._transfer_and_share(url, "")
            if transfer_result['success']:
                result = f"âœ… è½¬å­˜æˆåŠŸ\nèµ„æºæ ‡é¢˜ï¼š{transfer_result['title']}\nåˆ†äº«é“¾æ¥ï¼š{transfer_result['share_url']}"
            else:
                result = f"âŒ è½¬å­˜å¤±è´¥\n{transfer_result.get('error', 'æœªçŸ¥é”™è¯¯')}"
            yield event.plain_result(result)
        except Exception as e:
            logger.error(f"å¤„ç†è½¬å­˜æŒ‡ä»¤æ—¶å‘ç”Ÿé”™è¯¯: {str(e)}")
            yield event.plain_result(self.messages['transfer_error'])
    async def _search_resources(self, user_session_key: str, keyword: str, is_full_network: bool = False, pan_type: int = 0, page: int = 1) -> str:
        self._check_license()
        if not keyword or not keyword.strip():
            return self.messages['empty_keyword']
        if len(keyword) > 50:
            return self.messages['keyword_too_long']
        retry_count = 0
        while retry_count < self.max_retries:
            try:
                if is_full_network:
                    url = f"{self.base_url}/api/other/all_search"
                    params = {
                        "title": keyword
                    }
                else:
                    url = f"{self.base_url}/api/other/web_search"
                    params = {
                        "title": keyword,
                        "is_type": pan_type,
                        "is_show": 1
                    }
                headers = {
                    'User-Agent': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/131.0.0.0 Safari/537.36',
                    'Accept': 'text/event-stream',
                    'Accept-Language': 'zh-CN,zh;q=0.9,en;q=0.8',
                    'Referer': 'https://aliso.vip/',
                    'Origin': 'https://aliso.vip'
                }
                if self.api_key:
                    headers['Authorization'] = f'Bearer {self.api_key}'
                async with aiohttp.ClientSession() as session:
                    async with session.get(url, params=params, headers=headers, timeout=aiohttp.ClientTimeout(total=self.search_timeout)) as response:
                        if response.status == 200:
                            try:
                                content_type = response.headers.get('content-type', '')
                                if 'text/event-stream' in content_type:
                                    text = await response.text()
                                    parsed_data = self._parse_sse_response(text, keyword, page)
                                    self.user_sessions[user_session_key] = {
                                        'results': text,
                                        'keyword': keyword,
                                        'is_full_network': is_full_network,
                                        'pan_type': pan_type,
                                        'current_page': page,
                                        'total_pages': 1,
                                        'is_sse': True
                                    }
                                    return await self._format_search_results(user_session_key, parsed_data, keyword, is_full_network, page)
                                else:
                                    data = await response.json()
                                    self.user_sessions[user_session_key] = {
                                        'results': data,
                                        'keyword': keyword,
                                        'is_full_network': is_full_network,
                                        'pan_type': pan_type,
                                        'current_page': page,
                                        'total_pages': 1,
                                        'is_sse': False
                                    }
                                    return await self._format_search_results(user_session_key, data, keyword, is_full_network, page)
                            except Exception as e:
                                logger.error(
                                    f"è§£æå“åº”å¤±è´¥: {str(e)}, status={response.status}, content-type={content_type}")
                                return self.messages['parse_search_failed']
                        elif response.status == 404:
                            return self.messages['no_resources_found'].format(keyword)
                        elif response.status == 429:
                            retry_count += 1
                            if retry_count >= self.max_retries:
                                return self.messages['too_many_requests']
                            await asyncio.sleep(2 ** retry_count)
                            continue
                        else:
                            retry_count += 1
                            if retry_count >= self.max_retries:
                                return self.messages['search_service_unavailable'].format(response.status)
                            await asyncio.sleep(1)
                            continue
            except asyncio.TimeoutError:
                retry_count += 1
                if retry_count >= self.max_retries:
                    return self.messages['search_timeout']
                await asyncio.sleep(2 ** retry_count)
                continue
            except aiohttp.ClientError as e:
                retry_count += 1
                if retry_count >= self.max_retries:
                    logger.error(f"ç½‘ç»œè¯·æ±‚é”™è¯¯: {str(e)}")
                    return self.messages['network_error']
                await asyncio.sleep(2 ** retry_count)
                continue
            except Exception as e:
                logger.error(f"æœç´¢è¿‡ç¨‹ä¸­å‘ç”ŸæœªçŸ¥é”™è¯¯: {str(e)}")
                return self.messages['unknown_search_error'].format(str(e))
        return self.messages['search_service_unavailable_temporarily']
    async def _local_search(self, keyword: str) -> str:
        self._check_license()
        try:
            url = f"{self.base_url}/api/search/index"
            params = {
                "title": keyword,
                "page": 1,
                "page_size": 10
            }
            logger.info(f"æ­£åœ¨æœ¬åœ°æ•°æ®åº“æŸ¥æ‰¾: {keyword}")
            async with aiohttp.ClientSession() as session:
                async with session.get(url, params=params, timeout=aiohttp.ClientTimeout(total=5)) as response:
                    if response.status == 200:
                        data = await response.json()
                        if data.get('code') == 200 and data.get('data'):
                            result_data = data['data']
                            if isinstance(result_data, dict) and 'items' in result_data:
                                results = result_data['items']
                            elif isinstance(result_data, dict) and 'list' in result_data:
                                results = result_data['list']
                            elif isinstance(result_data, list):
                                results = result_data
                            else:
                                results = []
                            if len(results) == 0:
                                return f"âŒ æœ¬åœ°æ•°æ®åº“æœªæ‰¾åˆ°ç›¸å…³èµ„æº: {keyword}\n\nğŸ’¡ æç¤ºï¼šå¯ä»¥å°è¯•ä½¿ç”¨ã€æœ{keyword}ã€‘è¿›è¡Œå…¨ç½‘æœç´¢"
                            result_text = f"ğŸ” æœ¬åœ°æ•°æ®åº“æ‰¾åˆ° {len(results)} ä¸ªç›¸å…³èµ„æºï¼š\n\n"
                            for i, item in enumerate(results, 1):
                                title = item.get('title', 'æœªçŸ¥æ ‡é¢˜')
                                url_link = item.get('url', '')
                                is_time = item.get('is_time', 0)
                                pan_type_name = "æœªçŸ¥"
                                if 'quark.cn' in url_link:
                                    pan_type_name = "å¤¸å…‹"
                                elif 'pan.baidu.com' in url_link:
                                    pan_type_name = "ç™¾åº¦"
                                elif 'drive.uc.cn' in url_link:
                                    pan_type_name = "UC"
                                elif 'pan.xunlei.com' in url_link:
                                    pan_type_name = "è¿…é›·"
                                elif 'aliyundrive.com' in url_link or 'alipan.com' in url_link:
                                    pan_type_name = "é˜¿é‡Œ"
                                if is_time == 1:
                                    result_text += f"{i}. ã€{pan_type_name}ã€‘{title}\nğŸŒ é“¾æ¥: {url_link}\n\n"
                                else:
                                    result_text += f"{i}. ã€{pan_type_name}ã€‘{title}\nğŸ”— é“¾æ¥: {url_link}\n\n"
                            result_text += "â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n"
                            has_temp = any(item.get('is_time') == 1 for item in results)
                            if has_temp:
                                result_text += "ğŸŒ èµ„æºæ¥æºç½‘ç»œï¼Œ30åˆ†é’Ÿååˆ é™¤\n"
                                result_text += "â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n"
                            result_text += f"ğŸ’¡ æç¤ºï¼šç»“æœä¸æ»¡æ„ï¼Œè¯·è¾“å…¥ã€æœ{keyword}ã€‘ï¼Œè¿›è¡Œå…¨ç½‘æœç´¢"
                            return result_text
                        else:
                            return f"âŒ æœ¬åœ°æ•°æ®åº“æœªæ‰¾åˆ°ç›¸å…³èµ„æº\n\nğŸ’¡ æç¤ºï¼šå¯ä»¥å°è¯•ä½¿ç”¨ã€æœ{keyword}ã€‘è¿›è¡Œå…¨ç½‘æœç´¢"
                    elif response.status == 404:
                        return f"âŒ æœ¬åœ°æ•°æ®åº“æœªæ‰¾åˆ°ç›¸å…³èµ„æº\n\nğŸ’¡ æç¤ºï¼šå¯ä»¥å°è¯•ä½¿ç”¨ã€{keyword}ã€‘è¿›è¡Œå…¨ç½‘æœç´¢"
                    else:
                        return "âŒ æœç´¢æœåŠ¡å¼‚å¸¸ï¼Œè¯·ç¨åé‡è¯•"
        except asyncio.TimeoutError:
            logger.warning(f"æœ¬åœ°æœç´¢è¶…æ—¶ï¼ˆå¯èƒ½æ•°æ®åº“æ— ç»“æœï¼‰: {keyword}")
            return f"âŒ æœ¬åœ°æ•°æ®åº“æœªæ‰¾åˆ°ç›¸å…³èµ„æº: {keyword}\n\nğŸ’¡ æç¤ºï¼šå¯ä»¥å°è¯•ä½¿ç”¨ã€æœ{keyword}ã€‘è¿›è¡Œå…¨ç½‘æœç´¢"
        except Exception as e:
            logger.error(f"æœ¬åœ°æœç´¢å¤±è´¥: {str(e)}")
            return "âŒ æœç´¢å¤±è´¥ï¼Œè¯·ç¨åé‡è¯•"
    async def _full_network_search(self, keyword: str) -> str:
        self._check_license()
        if not keyword or not keyword.strip():
            return self.messages['empty_keyword']
        results = []
        success_count = 0
        for pan_name, pan_type in self.search_types.items():
            try:
                dummy_key = "dummy"
                result = await self._search_resources(dummy_key, keyword, is_full_network=False, pan_type=pan_type)
                if self.messages['no_resources_found'].format('') not in result and self.messages['search_failed'] not in result and self.messages['search_service_unavailable_temporarily'] not in result:
                    results.append(f"ã€{pan_name}ç½‘ç›˜ã€‘\n{result}")
                    success_count += 1
                elif self.messages['search_service_unavailable_temporarily'] in result:
                    return result
                await asyncio.sleep(0.5)
            except Exception as e:
                logger.error(f"æœç´¢{pan_name}ç½‘ç›˜æ—¶å‘ç”Ÿé”™è¯¯: {str(e)}")
                continue
        if success_count == 0:
            return self.messages['no_resources_found'].format(keyword)
        return self.messages['full_network_search_results'].format(keyword) + "\n\n".join(results)
    async def _format_search_results(self, user_session_key: str, data, keyword: str, is_full_network: bool, page: int = 1) -> str:
        try:
            result_list = []
            if isinstance(data, list):
                result_list = data
            elif isinstance(data, dict):
                if 'result' in data:
                    result_list = data['result']
                elif 'data' in data:
                    result_list = data['data']
                elif 'list' in data:
                    result_list = data['list']
                elif 'code' in data and data.get('code') == 0 and 'data' in data:
                    result_list = data['data']
            elif isinstance(data, str):
                if user_session_key in self.user_sessions:
                    session_data = self.user_sessions[user_session_key]
                    if session_data.get('is_sse', False):
                        lines = data.strip().split('\n')
                        data_lines = [
                            line for line in lines if line.startswith('data:')]
                        json_data_list = []
                        for data_line in data_lines:
                            json_str = data_line[5:].strip()
                            if json_str and json_str != '[DONE]':
                                import json
                                try:
                                    json_data = json.loads(json_str)
                                    json_data_list.append(json_data)
                                except json.JSONDecodeError:
                                    continue
                        combined_data = []
                        for json_data in json_data_list:
                            if isinstance(json_data, dict):
                                if 'url' in json_data:
                                    combined_data.append(json_data)
                                elif 'data' in json_data and isinstance(json_data['data'], list):
                                    combined_data.extend(json_data['data'])
                                else:
                                    combined_data.append(json_data)
                            elif isinstance(json_data, list):
                                combined_data.extend(json_data)
                        result_list = combined_data
            else:
                return self.messages['no_resources_found'].format(keyword)
            if not result_list:
                return self.messages['no_resources_found'].format(keyword)
            page_size = self.results_per_page
            total_results = len(result_list)
            total_pages = (total_results + page_size - 1) // page_size
            if user_session_key in self.user_sessions:
                self.user_sessions[user_session_key]['total_pages'] = total_pages
            if page < 1 or page > total_pages:
                return self.messages['invalid_page_number'].format(total_pages)
            start_index = (page - 1) * page_size
            end_index = min(start_index + page_size, total_results)
            current_page_results = result_list[start_index:end_index]
            formatted_results = await self._transfer_and_format_results(current_page_results, start_index)
            result_text = self.messages['search_results_header'].format(
                total_results) + '\n\n' + '\n\n'.join(formatted_results)
            result_text += '\n\n' + self.messages['search_results_separator'] + '\n' + self.messages['search_results_footer'] + '\n' + self.messages['search_results_separator_footer']
            result_text += '\n' + self.messages['search_results_website_promo'].format(self.base_url) + '\n' + self.messages['search_results_separator_footer']
            if self.enable_pagination:
                result_text += '\n' + self.messages['search_results_page_info'].format(
                    page, total_pages) + '\n' + self.messages['search_results_navigation']
            return result_text
        except Exception as e:
            logger.error(f"æ ¼å¼åŒ–æœç´¢ç»“æœæ—¶å‘ç”Ÿé”™è¯¯: {str(e)}")
            return self.messages['format_search_error']
    async def _transfer_and_format_results(self, results: list, start_index: int) -> list:
        if not self.enable_transfer or not self.api_key:
            return self._format_results_without_transfer(results, start_index)
        pan_types_needed = set()
        for item in results:
            url = item.get('url', '')
            if url:
                pan_type = self._identify_pan_type(url)
                if pan_type in ['quark', 'baidu', 'uc', 'xunlei', 'ali']:
                    pan_types_needed.add(pan_type)
        await self._prefetch_cookies(pan_types_needed)
        tasks = []
        for i, item in enumerate(results):
            global_index = start_index + i + 1
            title = item.get('title', self.messages['resource_title_default'])
            url = item.get('url', '')
            if url:
                pan_type = self._identify_pan_type(url)
                if pan_type in ['quark', 'baidu', 'uc', 'xunlei', 'ali']:
                    task = self._transfer_single_resource(global_index, title, url)
                    tasks.append(task)
                else:
                    tasks.append(self._format_single_result(global_index, title, url, None))
            else:
                tasks.append(self._format_single_result(global_index, title, '', None))
        results = await asyncio.gather(*tasks, return_exceptions=True)
        formatted = []
        for result in results:
            if isinstance(result, Exception):
                logger.error(f"è½¬å­˜ä»»åŠ¡å¼‚å¸¸: {str(result)}")
                formatted.append("âš ï¸ å¤„ç†å¤±è´¥")
            else:
                formatted.append(result)
        return formatted
    async def _transfer_single_resource(self, index: int, title: str, url: str) -> str:
        try:
            parsed_url = urlparse(url)
            query_params = parse_qs(parsed_url.query)
            pwd_code = query_params.get('pwd', [''])[0]
            transfer_result = await self._transfer_and_share(url, pwd_code)
            if transfer_result['success']:
                new_title = transfer_result['title']
                new_url = transfer_result['share_url']
                return f"{index}. {new_title}\nâœ… é“¾æ¥: {new_url}"
            else:
                return f"{index}. {title}\nâŒ è½¬å­˜å¤±è´¥ï¼Œè¯·å°è¯•æœç´¢å…¶ä»–ç½‘ç›˜"
        except Exception as e:
            logger.error(f"è½¬å­˜èµ„æºå¤±è´¥: {str(e)}")
            return f"{index}. {title}\nâŒ è½¬å­˜å¤±è´¥ï¼Œè¯·å°è¯•æœç´¢å…¶ä»–ç½‘ç›˜"
    async def _format_single_result(self, index: int, title: str, url: str, transfer_result) -> str:
        if url:
            return f"{index}. {title}\né“¾æ¥: {url}"
        return f"{index}. {title}"
    def _format_results_without_transfer(self, results: list, start_index: int) -> list:
        formatted = []
        for i, item in enumerate(results):
            global_index = start_index + i + 1
            title = item.get('title', self.messages['resource_title_default'])
            url = item.get('url', '')
            if url:
                formatted.append(f"{global_index}. {title}\nğŸ”— é“¾æ¥: {url}")
            else:
                formatted.append(f"{global_index}. {title}")
        return formatted
    def _identify_pan_type(self, url: str) -> str:
        domain_patterns = {
            'quark': ['pan.quark.cn'],
            'ali': ['www.alipan.com', 'www.aliyundrive.com'],
            'baidu': ['pan.baidu.com'],
            'uc': ['drive.uc.cn', 'fast.uc.cn'],
            'xunlei': ['pan.xunlei.com']
        }
        lower_url = url.lower()
        for pan_type, patterns in domain_patterns.items():
            for pattern in patterns:
                if pattern in lower_url:
                    return pan_type
        return 'quark'
    async def _prefetch_cookies(self, pan_types: set):
        tasks = []
        for pan_type in pan_types:
            cache_entry = self._cookie_cache.get(pan_type)
            if not cache_entry or (time.time() - cache_entry[1] > 300):
                tasks.append(self._get_actual_cookie_value(pan_type))
        if tasks:
            await asyncio.gather(*tasks, return_exceptions=True)
    async def _get_actual_cookie_value(self, pan_type: str) -> str:
        cache_entry = self._cookie_cache.get(pan_type)
        if cache_entry and (time.time() - cache_entry[1] < 300):
            return cache_entry[0]
        api_endpoints = {
            'quark': 'quark',
            'baidu': 'baidu',
            'uc': 'uc',
            'xunlei': 'xunlei',
            'ali': 'ali'
        }
        if pan_type not in api_endpoints:
            logger.warning(f"ä¸æ”¯æŒçš„ç½‘ç›˜ç±»å‹: {pan_type}")
            return ""
        try:
            async with aiohttp.ClientSession() as session:
                api_url = f"{self.base_url}/api/GetCookie/{api_endpoints[pan_type]}"
                async with session.get(
                    api_url,
                    timeout=aiohttp.ClientTimeout(total=10)
                ) as response:
                    if response.status == 200:
                        result = await response.json()
                        if result.get('code') == 200:
                            cookie_key = f"{pan_type}_cookie"
                            actual_cookie = result.get('data', {}).get(cookie_key, "")
                            if actual_cookie:
                                self._cookie_cache[pan_type] = (actual_cookie, time.time())
                                logger.info(f"âœ… è·å–{pan_type}ç½‘ç›˜CookieæˆåŠŸ")
                                return actual_cookie
                            else:
                                return ""
                        else:
                            return ""
                    else:
                        return ""
        except Exception as e:
            logger.error(f"âŒ è·å–{pan_type}ç½‘ç›˜Cookieå¼‚å¸¸: {str(e)}")
            return ""
    async def _get_cookie_from_database(self, pan_type: str) -> str:
        api_endpoints = {
            'quark': 'quark',
            'baidu': 'baidu',
            'uc': 'uc',
            'xunlei': 'xunlei',
            'ali': 'ali'
        }
        if pan_type not in api_endpoints:
            logger.warning(f"ä¸æ”¯æŒçš„ç½‘ç›˜ç±»å‹: {pan_type}")
            return ""
        try:
            async with aiohttp.ClientSession() as session:
                api_url = f"{self.base_url}/api/GetCookie/{api_endpoints[pan_type]}"
                async with session.get(
                    api_url,
                    timeout=aiohttp.ClientTimeout(total=10)
                ) as response:
                    if response.status == 200:
                        return "API_SUCCESS"
                    else:
                        return ""
        except Exception as e:
            logger.error(f"âŒ è·å–{pan_type}ç½‘ç›˜Cookieå¼‚å¸¸: {str(e)}")
            return ""
    def _parse_sse_response(self, text: str, keyword: str, page: int = 1) -> str:
        try:
            lines = text.strip().split('\n')
            data_lines = [line for line in lines if line.startswith('data:')]
            json_data_list = []
            for data_line in data_lines:
                json_str = data_line[5:].strip()
                if json_str and json_str != '[DONE]':
                    import json
                    try:
                        json_data = json.loads(json_str)
                        json_data_list.append(json_data)
                    except json.JSONDecodeError:
                        continue
            if not json_data_list:
                return []
            combined_data = []
            for json_data in json_data_list:
                if isinstance(json_data, dict):
                    if 'url' in json_data:
                        combined_data.append(json_data)
                    elif 'data' in json_data and isinstance(json_data['data'], list):
                        combined_data.extend(json_data['data'])
                    else:
                        combined_data.append(json_data)
                elif isinstance(json_data, list):
                    combined_data.extend(json_data)
            return combined_data
        except Exception as e:
            logger.error(f"è§£æSSEå“åº”æ—¶å‘ç”Ÿé”™è¯¯: {str(e)}")
            return []
    async def _transfer_and_share(self, url: str, code: str = "") -> dict:
        try:
            api_key = self.api_key
            if not api_key:
                return {'success': False, 'error': self.messages['api_key_not_configured']}
            pan_type = self._identify_pan_type(url)
            actual_cookie = ""
            cache_entry = self._cookie_cache.get(pan_type)
            if cache_entry and (time.time() - cache_entry[1] < 300):
                actual_cookie = cache_entry[0]
            else:
                cookie_status = await self._get_cookie_from_database(pan_type)
                if not cookie_status:
                    logger.warning(f"âŒ è·å–{pan_type}ç½‘ç›˜Cookieå¤±è´¥")
                    return {'success': False, 'error': 'æŠ±æ­‰ï¼Œcookieè¿‡æœŸï¼Œè¯·è”ç³»ç¾¤ä¸»ï¼'}
                else:
                    actual_cookie = await self._get_actual_cookie_value(pan_type)
                    if not actual_cookie:
                        logger.warning(f"âŒ è·å–{pan_type}ç½‘ç›˜Cookieå¤±è´¥")
                        return {'success': False, 'error': 'æŠ±æ­‰ï¼Œcookieè¿‡æœŸï¼Œè¯·è”ç³»ç¾¤ä¸»ï¼'}
            transfer_data = {
                'url': url,
                'code': code,
                'expired_type': 2,
                'isType': 0,
                'api_key': api_key,
                'isSave': 1
            }
            headers = {
                'Content-Type': 'application/json'
            }
            async with aiohttp.ClientSession() as session:
                async with session.post(
                    f"{self.base_url}/api/open/transfer",
                    json=transfer_data,
                    headers=headers,
                    timeout=aiohttp.ClientTimeout(total=30)
                ) as response:
                    if response.status == 200:
                        result = await response.json()
                        if result.get('code') == 200:
                            return {
                                'success': True,
                                'title': result['data']['title'],
                                'share_url': result['data']['share_url']
                            }
                        else:
                            return {
                                'success': False,
                                'error': result.get('message', self.messages['unknown_error'])
                            }
                    else:
                        return {
                            'success': False,
                            'error': self.messages['transfer_service_error'].format(response.status)
                        }
        except asyncio.TimeoutError:
            return {'success': False, 'error': self.messages['transfer_timeout']}
        except Exception as e:
            logger.error(f"è½¬å­˜è¿‡ç¨‹ä¸­å‘ç”Ÿé”™è¯¯ï¼š{str(e)}")
            return {'success': False, 'error': self.messages['transfer_process_error'].format(str(e))}
    @filter.command("ä½¿ç”¨æ–¹æ³•")
    async def show_usage(self, event: AstrMessageEvent):
        try:
            usage_info = f"""ğŸ“– å¿ƒæ‚¦æœç´¢æœºå™¨äººä½¿ç”¨æŒ‡å—
ğŸ” åŸºç¡€æœç´¢æŒ‡ä»¤ï¼š
â€¢ æ‰¾ + å…³é”®è¯ â†’ æœ¬åœ°æœç´¢ï¼ˆåªæŸ¥æœ¬åœ°æ•°æ®åº“ï¼Œé€Ÿåº¦å¿«ï¼‰
  ç¤ºä¾‹ï¼šæ‰¾å¤ä»‡è€…è”ç›Ÿ
â€¢ æœ + å…³é”®è¯ â†’ å…¨ç½‘æœç´¢ï¼ˆä»å¤–éƒ¨APIæœç´¢ï¼‰
  ç¤ºä¾‹ï¼šæœå¤ä»‡è€…è”ç›Ÿ
â€¢ ç™¾åº¦ + å…³é”®è¯ â†’ æœç´¢ç™¾åº¦ç½‘ç›˜èµ„æº
  ç¤ºä¾‹ï¼šç™¾åº¦å¤ä»‡è€…è”ç›Ÿ
â€¢ uc/UC + å…³é”®è¯ â†’ æœç´¢UCç½‘ç›˜èµ„æº
  ç¤ºä¾‹ï¼šucå¤ä»‡è€…è”ç›Ÿ
â€¢ è¿…é›· + å…³é”®è¯ â†’ æœç´¢è¿…é›·ç½‘ç›˜èµ„æº
  ç¤ºä¾‹ï¼šè¿…é›·å¤ä»‡è€…è”ç›Ÿ
ğŸ“„ ç¿»é¡µæŒ‡ä»¤ï¼š
â€¢ ä¸Š æˆ– 0 â†’ æŸ¥çœ‹ä¸Šä¸€é¡µ
â€¢ ä¸‹ æˆ– 1 â†’ æŸ¥çœ‹ä¸‹ä¸€é¡µ
ğŸ’¡ æœç´¢æŠ€å·§ï¼š
â€¢ ä¼˜å…ˆä½¿ç”¨"æ‰¾"è¿›è¡Œå¿«é€ŸæŸ¥è¯¢
â€¢ æœ¬åœ°æ— ç»“æœæ—¶å†ä½¿ç”¨"æœ"è¿›è¡Œå…¨ç½‘æœç´¢
â€¢ å…³é”®è¯å°½é‡ç®€çŸ­å‡†ç¡®
ğŸ”— é“¾æ¥çŠ¶æ€è¯´æ˜ï¼š
â€¢ âœ… = è½¬å­˜æˆåŠŸï¼ˆå·²è½¬å­˜å¹¶ç”Ÿæˆæ–°é“¾æ¥ï¼‰
â€¢ âŒ = è½¬å­˜å¤±è´¥ï¼ˆè½¬å­˜å¤±è´¥ï¼Œè¯·å°è¯•æœç´¢å…¶ä»–ç½‘ç›˜ï¼‰
â€¢ ğŸ”— = ç›´æ¥åˆ†äº«ï¼ˆæœªå¯ç”¨è½¬å­˜ï¼‰
â€¢ ğŸŒ = ä¸´æ—¶èµ„æºï¼ˆ30åˆ†é’Ÿååˆ é™¤ï¼‰
â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
æ›´å¤šèµ„æºè¯·è®¿é—®ï¼š{self.base_url}"""
            yield event.plain_result(usage_info)
        except Exception as e:
            logger.error(f"æ˜¾ç¤ºä½¿ç”¨æ–¹æ³•æ—¶å‘ç”Ÿé”™è¯¯: {str(e)}")
            yield event.plain_result("âŒ è·å–ä½¿ç”¨æ–¹æ³•å¤±è´¥ï¼Œè¯·ç¨åé‡è¯•")
    async def terminate(self):
        logger.info("å¿ƒæ‚¦æœç´¢æœºå™¨äººæ’ä»¶å·²ç»ˆæ­¢")